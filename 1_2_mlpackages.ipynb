{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARET\n",
    "\n",
    "![gather](fig/caret.jpg \"title-1\")\n",
    "\n",
    "**CARET** is a package that we are going to use extensively in the next lessons. It provides a unified framework to build predictive models leveraging on the large list of packages belonging to the **R** ecosystem. \n",
    "\n",
    "Each one of these packages has its particular interface and to use it you have to adapt your code to this interface.  \n",
    "\n",
    "**CARET** provides a standard interface with these packages and you have only to adapt your code to this unique interface: if you use **CARET** and you want to change the statistical methods / implementation used by your code, with **CARET** you should only have to change some parameters and your code will work out-of-the-box.\n",
    "\n",
    "To use this package you have simply have to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"src/lib.R\")\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve all the models supported by **CARET** using the **getModelInfo** function, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Number of models: 238'"
      ],
      "text/latex": [
       "'Number of models: 238'"
      ],
      "text/markdown": [
       "'Number of models: 238'"
      ],
      "text/plain": [
       "[1] \"Number of models: 238\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Supported Models: ada, AdaBag, AdaBoost.M1, adaboost, amdai, ANFIS, avNNet, awnb, awtan, bag, bagEarth, bagEarthGCV, bagFDA, bagFDAGCV, bam, bartMachine, bayesglm, binda, blackboost, blasso, blassoAveraged, bridge, brnn, BstLm, bstSm, bstTree, C5.0, C5.0Cost, C5.0Rules, C5.0Tree, cforest, chaid, CSimca, ctree, ctree2, cubist, dda, deepboost, DENFIS, dnn, dwdLinear, dwdPoly, dwdRadial, earth, elm, enet, evtree, extraTrees, fda, FH.GBML, FIR.DM, foba, FRBCS.CHI, FRBCS.W, FS.HGD, gam, gamboost, gamLoess, gamSpline, gaussprLinear, gaussprPoly, gaussprRadial, gbm_h2o, gbm, gcvEarth, GFS.FR.MOGUL, GFS.LT.RS, GFS.THRIFT, glm.nb, glm, glmboost, glmnet_h2o, glmnet, glmStepAIC, gpls, hda, hdda, hdrda, HYFIS, icr, J48, JRip, kernelpls, kknn, knn, krlsPoly, krlsRadial, lars, lars2, lasso, lda, lda2, leapBackward, leapForward, leapSeq, Linda, lm, lmStepAIC, LMT, loclda, logicBag, LogitBoost, logreg, lssvmLinear, lssvmPoly, lssvmRadial, lvq, M5, M5Rules, manb, mda, Mlda, mlp, mlpKerasDecay, mlpKerasDecayCost, mlpKerasDropout, mlpKerasDropoutCost, mlpML, mlpSGD, mlpWeightDecay, mlpWeightDecayML, monmlp, msaenet, multinom, mxnet, mxnetAdam, naive_bayes, nb, nbDiscrete, nbSearch, neuralnet, nnet, nnls, nodeHarvest, null, OneR, ordinalNet, ORFlog, ORFpls, ORFridge, ORFsvm, ownn, pam, parRF, PART, partDSA, pcaNNet, pcr, pda, pda2, penalized, PenalizedLDA, plr, pls, plsRglm, polr, ppr, PRIM, protoclass, pythonKnnReg, qda, QdaCov, qrf, qrnn, randomGLM, ranger, rbf, rbfDDA, Rborist, rda, regLogistic, relaxo, rf, rFerns, RFlda, rfRules, ridge, rlda, rlm, rmda, rocc, rotationForest, rotationForestCp, rpart, rpart1SE, rpart2, rpartCost, rpartScore, rqlasso, rqnc, RRF, RRFglobal, rrlda, RSimca, rvmLinear, rvmPoly, rvmRadial, SBC, sda, sdwd, simpls, SLAVE, slda, smda, snn, sparseLDA, spikeslab, spls, stepLDA, stepQDA, superpc, svmBoundrangeString, svmExpoString, svmLinear, svmLinear2, svmLinear3, svmLinearWeights, svmLinearWeights2, svmPoly, svmRadial, svmRadialCost, svmRadialSigma, svmRadialWeights, svmSpectrumString, tan, tanSearch, treebag, vbmpRadial, vglmAdjCat, vglmContRatio, vglmCumulative, widekernelpls, WM, wsrf, xgbDART, xgbLinear, xgbTree, xyf'"
      ],
      "text/latex": [
       "'Supported Models: ada, AdaBag, AdaBoost.M1, adaboost, amdai, ANFIS, avNNet, awnb, awtan, bag, bagEarth, bagEarthGCV, bagFDA, bagFDAGCV, bam, bartMachine, bayesglm, binda, blackboost, blasso, blassoAveraged, bridge, brnn, BstLm, bstSm, bstTree, C5.0, C5.0Cost, C5.0Rules, C5.0Tree, cforest, chaid, CSimca, ctree, ctree2, cubist, dda, deepboost, DENFIS, dnn, dwdLinear, dwdPoly, dwdRadial, earth, elm, enet, evtree, extraTrees, fda, FH.GBML, FIR.DM, foba, FRBCS.CHI, FRBCS.W, FS.HGD, gam, gamboost, gamLoess, gamSpline, gaussprLinear, gaussprPoly, gaussprRadial, gbm\\_h2o, gbm, gcvEarth, GFS.FR.MOGUL, GFS.LT.RS, GFS.THRIFT, glm.nb, glm, glmboost, glmnet\\_h2o, glmnet, glmStepAIC, gpls, hda, hdda, hdrda, HYFIS, icr, J48, JRip, kernelpls, kknn, knn, krlsPoly, krlsRadial, lars, lars2, lasso, lda, lda2, leapBackward, leapForward, leapSeq, Linda, lm, lmStepAIC, LMT, loclda, logicBag, LogitBoost, logreg, lssvmLinear, lssvmPoly, lssvmRadial, lvq, M5, M5Rules, manb, mda, Mlda, mlp, mlpKerasDecay, mlpKerasDecayCost, mlpKerasDropout, mlpKerasDropoutCost, mlpML, mlpSGD, mlpWeightDecay, mlpWeightDecayML, monmlp, msaenet, multinom, mxnet, mxnetAdam, naive\\_bayes, nb, nbDiscrete, nbSearch, neuralnet, nnet, nnls, nodeHarvest, null, OneR, ordinalNet, ORFlog, ORFpls, ORFridge, ORFsvm, ownn, pam, parRF, PART, partDSA, pcaNNet, pcr, pda, pda2, penalized, PenalizedLDA, plr, pls, plsRglm, polr, ppr, PRIM, protoclass, pythonKnnReg, qda, QdaCov, qrf, qrnn, randomGLM, ranger, rbf, rbfDDA, Rborist, rda, regLogistic, relaxo, rf, rFerns, RFlda, rfRules, ridge, rlda, rlm, rmda, rocc, rotationForest, rotationForestCp, rpart, rpart1SE, rpart2, rpartCost, rpartScore, rqlasso, rqnc, RRF, RRFglobal, rrlda, RSimca, rvmLinear, rvmPoly, rvmRadial, SBC, sda, sdwd, simpls, SLAVE, slda, smda, snn, sparseLDA, spikeslab, spls, stepLDA, stepQDA, superpc, svmBoundrangeString, svmExpoString, svmLinear, svmLinear2, svmLinear3, svmLinearWeights, svmLinearWeights2, svmPoly, svmRadial, svmRadialCost, svmRadialSigma, svmRadialWeights, svmSpectrumString, tan, tanSearch, treebag, vbmpRadial, vglmAdjCat, vglmContRatio, vglmCumulative, widekernelpls, WM, wsrf, xgbDART, xgbLinear, xgbTree, xyf'"
      ],
      "text/markdown": [
       "'Supported Models: ada, AdaBag, AdaBoost.M1, adaboost, amdai, ANFIS, avNNet, awnb, awtan, bag, bagEarth, bagEarthGCV, bagFDA, bagFDAGCV, bam, bartMachine, bayesglm, binda, blackboost, blasso, blassoAveraged, bridge, brnn, BstLm, bstSm, bstTree, C5.0, C5.0Cost, C5.0Rules, C5.0Tree, cforest, chaid, CSimca, ctree, ctree2, cubist, dda, deepboost, DENFIS, dnn, dwdLinear, dwdPoly, dwdRadial, earth, elm, enet, evtree, extraTrees, fda, FH.GBML, FIR.DM, foba, FRBCS.CHI, FRBCS.W, FS.HGD, gam, gamboost, gamLoess, gamSpline, gaussprLinear, gaussprPoly, gaussprRadial, gbm_h2o, gbm, gcvEarth, GFS.FR.MOGUL, GFS.LT.RS, GFS.THRIFT, glm.nb, glm, glmboost, glmnet_h2o, glmnet, glmStepAIC, gpls, hda, hdda, hdrda, HYFIS, icr, J48, JRip, kernelpls, kknn, knn, krlsPoly, krlsRadial, lars, lars2, lasso, lda, lda2, leapBackward, leapForward, leapSeq, Linda, lm, lmStepAIC, LMT, loclda, logicBag, LogitBoost, logreg, lssvmLinear, lssvmPoly, lssvmRadial, lvq, M5, M5Rules, manb, mda, Mlda, mlp, mlpKerasDecay, mlpKerasDecayCost, mlpKerasDropout, mlpKerasDropoutCost, mlpML, mlpSGD, mlpWeightDecay, mlpWeightDecayML, monmlp, msaenet, multinom, mxnet, mxnetAdam, naive_bayes, nb, nbDiscrete, nbSearch, neuralnet, nnet, nnls, nodeHarvest, null, OneR, ordinalNet, ORFlog, ORFpls, ORFridge, ORFsvm, ownn, pam, parRF, PART, partDSA, pcaNNet, pcr, pda, pda2, penalized, PenalizedLDA, plr, pls, plsRglm, polr, ppr, PRIM, protoclass, pythonKnnReg, qda, QdaCov, qrf, qrnn, randomGLM, ranger, rbf, rbfDDA, Rborist, rda, regLogistic, relaxo, rf, rFerns, RFlda, rfRules, ridge, rlda, rlm, rmda, rocc, rotationForest, rotationForestCp, rpart, rpart1SE, rpart2, rpartCost, rpartScore, rqlasso, rqnc, RRF, RRFglobal, rrlda, RSimca, rvmLinear, rvmPoly, rvmRadial, SBC, sda, sdwd, simpls, SLAVE, slda, smda, snn, sparseLDA, spikeslab, spls, stepLDA, stepQDA, superpc, svmBoundrangeString, svmExpoString, svmLinear, svmLinear2, svmLinear3, svmLinearWeights, svmLinearWeights2, svmPoly, svmRadial, svmRadialCost, svmRadialSigma, svmRadialWeights, svmSpectrumString, tan, tanSearch, treebag, vbmpRadial, vglmAdjCat, vglmContRatio, vglmCumulative, widekernelpls, WM, wsrf, xgbDART, xgbLinear, xgbTree, xyf'"
      ],
      "text/plain": [
       "[1] \"Supported Models: ada, AdaBag, AdaBoost.M1, adaboost, amdai, ANFIS, avNNet, awnb, awtan, bag, bagEarth, bagEarthGCV, bagFDA, bagFDAGCV, bam, bartMachine, bayesglm, binda, blackboost, blasso, blassoAveraged, bridge, brnn, BstLm, bstSm, bstTree, C5.0, C5.0Cost, C5.0Rules, C5.0Tree, cforest, chaid, CSimca, ctree, ctree2, cubist, dda, deepboost, DENFIS, dnn, dwdLinear, dwdPoly, dwdRadial, earth, elm, enet, evtree, extraTrees, fda, FH.GBML, FIR.DM, foba, FRBCS.CHI, FRBCS.W, FS.HGD, gam, gamboost, gamLoess, gamSpline, gaussprLinear, gaussprPoly, gaussprRadial, gbm_h2o, gbm, gcvEarth, GFS.FR.MOGUL, GFS.LT.RS, GFS.THRIFT, glm.nb, glm, glmboost, glmnet_h2o, glmnet, glmStepAIC, gpls, hda, hdda, hdrda, HYFIS, icr, J48, JRip, kernelpls, kknn, knn, krlsPoly, krlsRadial, lars, lars2, lasso, lda, lda2, leapBackward, leapForward, leapSeq, Linda, lm, lmStepAIC, LMT, loclda, logicBag, LogitBoost, logreg, lssvmLinear, lssvmPoly, lssvmRadial, lvq, M5, M5Rules, manb, mda, Mlda, mlp, mlpKerasDecay, mlpKerasDecayCost, mlpKerasDropout, mlpKerasDropoutCost, mlpML, mlpSGD, mlpWeightDecay, mlpWeightDecayML, monmlp, msaenet, multinom, mxnet, mxnetAdam, naive_bayes, nb, nbDiscrete, nbSearch, neuralnet, nnet, nnls, nodeHarvest, null, OneR, ordinalNet, ORFlog, ORFpls, ORFridge, ORFsvm, ownn, pam, parRF, PART, partDSA, pcaNNet, pcr, pda, pda2, penalized, PenalizedLDA, plr, pls, plsRglm, polr, ppr, PRIM, protoclass, pythonKnnReg, qda, QdaCov, qrf, qrnn, randomGLM, ranger, rbf, rbfDDA, Rborist, rda, regLogistic, relaxo, rf, rFerns, RFlda, rfRules, ridge, rlda, rlm, rmda, rocc, rotationForest, rotationForestCp, rpart, rpart1SE, rpart2, rpartCost, rpartScore, rqlasso, rqnc, RRF, RRFglobal, rrlda, RSimca, rvmLinear, rvmPoly, rvmRadial, SBC, sda, sdwd, simpls, SLAVE, slda, smda, snn, sparseLDA, spikeslab, spls, stepLDA, stepQDA, superpc, svmBoundrangeString, svmExpoString, svmLinear, svmLinear2, svmLinear3, svmLinearWeights, svmLinearWeights2, svmPoly, svmRadial, svmRadialCost, svmRadialSigma, svmRadialWeights, svmSpectrumString, tan, tanSearch, treebag, vbmpRadial, vglmAdjCat, vglmContRatio, vglmCumulative, widekernelpls, WM, wsrf, xgbDART, xgbLinear, xgbTree, xyf\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models <- getModelInfo()\n",
    "sprintf(\"Number of models: %d\", names(models) %>% length)\n",
    "sprintf(\"Supported Models: %s\", names(models) %>% paste(collapse = \", \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WOW** 238 models! Note that not all these models are implemented in **CARET** but the majority is implemented in an external library and you have to install the related package if you want to use it. The result of **getModelInfo** can be used to find which package you have to install to use a particular method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Linear Regression'"
      ],
      "text/latex": [
       "'Linear Regression'"
      ],
      "text/markdown": [
       "'Linear Regression'"
      ],
      "text/plain": [
       "[1] \"Linear Regression\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models$lm$label\n",
    "models$lm$library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'k-Nearest Neighbors'"
      ],
      "text/latex": [
       "'k-Nearest Neighbors'"
      ],
      "text/markdown": [
       "'k-Nearest Neighbors'"
      ],
      "text/plain": [
       "[1] \"k-Nearest Neighbors\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'kknn'"
      ],
      "text/latex": [
       "'kknn'"
      ],
      "text/markdown": [
       "'kknn'"
      ],
      "text/plain": [
       "[1] \"kknn\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models$kknn$label\n",
    "models$kknn$library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we want to use 'k-Nearest Neighbors' model we have to first install the **kknn** package (in the binder image we've already installed it!). On the contrary, if we want to use **Linear Regression** we don't have to install anything (**CARET** uses the standard R function **lm**)\n",
    "\n",
    "Ok nice, but how to fit a model with **CARET**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear Regression \n",
       "\n",
       "32 samples\n",
       "10 predictors\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 32, 32, 32, 32, 32, 32, ... \n",
       "Resampling results:\n",
       "\n",
       "  RMSE       Rsquared   MAE      \n",
       "  0.9400267  0.7465069  0.6975435\n",
       "\n",
       "Tuning parameter 'intercept' was held constant at a value of TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(x = mtcars %>% select(-cyl), \n",
    "      y= mtcars$cyl, \n",
    "      method = \"lm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model output is quite verbose, here we focus only on the last line...what is a **tuning parameter**? In a nutshell, it's a parameter on which **CARET** will try to optimize the fitted model (we'll see more on this topic in the second lesson)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model supported by **CARET** has its **tuning parameters**. To see which ones are the supported parameters you can explore the output of getModelInfo(). Here the **tuning parameters** of the *Linear Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>parameter</th><th scope=col>class</th><th scope=col>label</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>intercept</td><td>logical  </td><td>intercept</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " parameter & class & label\\\\\n",
       "\\hline\n",
       "\t intercept & logical   & intercept\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "parameter | class | label | \n",
       "|---|\n",
       "| intercept | logical   | intercept | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  parameter class   label    \n",
       "1 intercept logical intercept"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models$lm$parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one parameter (*intercept*), with a logical (*True* or *False*) class that controls (as the name suggests) the value of the intercept in the fitted model. To set the value of a **tuning parameter** you can use the *tuneGrid* parameter as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = .outcome ~ ., data = dat)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)          mpg         disp           hp         drat           wt  \n",
       "  12.107199    -0.004857     0.004610     0.003723    -0.427435    -0.222489  \n",
       "       qsec           vs           am         gear         carb  \n",
       "  -0.187945    -0.644076    -0.500770    -0.500323     0.179872  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(x = mtcars %>% select(-cyl), \n",
    "      y= mtcars$cyl, \n",
    "      method = \"lm\", \n",
    "      tuneGrid = data.frame(intercept = T))$finalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = .outcome ~ 0 + ., data = dat)\n",
       "\n",
       "Coefficients:\n",
       "      mpg       disp         hp       drat         wt       qsec         vs  \n",
       " 0.027136   0.008235   0.009147  -0.008767  -0.463077   0.276909  -1.401723  \n",
       "       am       gear       carb  \n",
       "-0.452727  -0.233211   0.221562  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(x = mtcars %>% select(-cyl), \n",
    "      y= mtcars$cyl, \n",
    "      method = \"lm\", \n",
    "      tuneGrid = data.frame(intercept = F))$finalModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that selecting the *finalModel* element of the *train* function result you can obtain the fitted model description.\n",
    "\n",
    "Often the **tuning parameters** supported by **CARET** do not cover all the parameters of the underlying fitting procedure. If you want to use a parameter not covered by **CARET** you can put it directly in the *train* function. As example consider the *subset* parameter in the *lm* function, you can provide it to **CARET** as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = .outcome ~ ., data = dat)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)          mpg         disp           hp         drat           wt  \n",
       "  12.107199    -0.004857     0.004610     0.003723    -0.427435    -0.222489  \n",
       "       qsec           vs           am         gear         carb  \n",
       "  -0.187945    -0.644076    -0.500770    -0.500323     0.179872  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(x = mtcars %>% select(-cyl), y= mtcars$cyl, method = \"lm\")$finalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = .outcome ~ ., data = dat, subset = ..1)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)          mpg         disp           hp         drat           wt  \n",
       "    9.63646     -0.54925      0.02618     -0.03921      3.51626      0.17568  \n",
       "       qsec           vs           am         gear         carb  \n",
       "   -0.08000      0.08408      0.82914     -1.41601           NA  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(x = mtcars %>% select(-cyl), y= mtcars$cyl, method = \"lm\", subset = 1:10)$finalModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOY Datasets\n",
    "\n",
    "In the following lessons we are going to use some simple datasets, that have been developed to challenge the simplest classification models.\n",
    "\n",
    "These datasets will be generated leveraging some of the functions provided by the R package [**mlbench**](https://cran.r-project.org/web/packages/mlbench/index.html).\n",
    "\n",
    "The full code to generate these datasets is contained the *.R* source file *src/lib.R*. Note that to correctly source this file you should set the working folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load all the datasets using the *get_full_dataset* function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x</th><th scope=col>y</th><th scope=col>class</th><th scope=col>type</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.3041773 </td><td>0.01479065</td><td>class_2   </td><td>normal    </td></tr>\n",
       "\t<tr><td>0.6819006 </td><td>0.90490897</td><td>class_1   </td><td>normal    </td></tr>\n",
       "\t<tr><td>0.2635762 </td><td>0.37815276</td><td>class_2   </td><td>normal    </td></tr>\n",
       "\t<tr><td>0.8225329 </td><td>0.65185947</td><td>class_1   </td><td>normal    </td></tr>\n",
       "\t<tr><td>0.8422131 </td><td>0.72926949</td><td>class_1   </td><td>normal    </td></tr>\n",
       "\t<tr><td>0.1859285 </td><td>0.22599968</td><td>class_2   </td><td>normal    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " x & y & class & type\\\\\n",
       "\\hline\n",
       "\t 0.3041773  & 0.01479065 & class\\_2  & normal    \\\\\n",
       "\t 0.6819006  & 0.90490897 & class\\_1  & normal    \\\\\n",
       "\t 0.2635762  & 0.37815276 & class\\_2  & normal    \\\\\n",
       "\t 0.8225329  & 0.65185947 & class\\_1  & normal    \\\\\n",
       "\t 0.8422131  & 0.72926949 & class\\_1  & normal    \\\\\n",
       "\t 0.1859285  & 0.22599968 & class\\_2  & normal    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x | y | class | type | \n",
       "|---|---|---|---|---|---|\n",
       "| 0.3041773  | 0.01479065 | class_2    | normal     | \n",
       "| 0.6819006  | 0.90490897 | class_1    | normal     | \n",
       "| 0.2635762  | 0.37815276 | class_2    | normal     | \n",
       "| 0.8225329  | 0.65185947 | class_1    | normal     | \n",
       "| 0.8422131  | 0.72926949 | class_1    | normal     | \n",
       "| 0.1859285  | 0.22599968 | class_2    | normal     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x         y          class   type  \n",
       "1 0.3041773 0.01479065 class_2 normal\n",
       "2 0.6819006 0.90490897 class_1 normal\n",
       "3 0.2635762 0.37815276 class_2 normal\n",
       "4 0.8225329 0.65185947 class_1 normal\n",
       "5 0.8422131 0.72926949 class_1 normal\n",
       "6 0.1859285 0.22599968 class_2 normal"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df <- get_full_dataset()\n",
    "full_df %>% head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot its content using **ggplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAADFBMVEUAAAAAAP//AAD///9D\npfB4AAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO2d2YLjKAxF3d3//88zVdnjDbCA\nK+mch5neKgFJFy12nOUfAFxmmb0AgAggJAADEBKAAQgJwACEBGAAQgIwACEBGICQAAxASAAG\nICQAA4II6XsbQbYViCW4U4JuLui2HBPdI0H3F3RbjonuEe/7W/7n371w+PnV6/ePXz7/DzNZ\nnk76cMrTX959FGH5dx8tX79//dL9NgPw6aRv53iXkfsIW17/X3Z+73yHUTg43UI4yfkOjoS0\nPMoG53uMwZeQls/azr+LnO/gLCPdf+d8lxHYyEj3X5ORBCgTkvttBmBbSHHqb+c72BguMGyQ\nZNspj9Lbv3+87+B9/P35e8bfUnyddm/OISMBwB2EBGAAQgIwACEBGICQAAxASAAGICQAAxAS\ngAEICcAAhARgAEICMAAhARiAkAAMQEgABiAkAAMQEoABCAnAAIQEYABCAjAAIQEYgJAADEBI\nAAYgJAADEguJx91FZJZX88bS8vfv37y7d0WFOKZ5NW0o/VgcJbmgQhzzvJo2khCSF2o8hZCG\ng5C8gJC0oUf6QHT08vOw/Rpx0CONRzR05iB6rPwuq2ptTO1gIqKF7n1ZHo48/RXCALSFNHsZ\nJbhYJOxhdVaLRqzosrZwsUjYYfnz54+dkgRjQXRZG/hYJWzyoyMzJWn2IaLLWuNkmbCFpZDg\nGnjBMQhJB7zgGbseSQM3hdwatwtf4dgJ7cTatJ/Rwhqv617h2Qnwi6Nh9xqny17h2gnwi2sf\nOl32CtdOgF9c+9Dpsle4dgLc8Fyee133Cs9OgDuOZyduF77CsRPAPwQfgAEICcAAhARgAEIC\nMAAhQULsJ1MICfLR4VoJQoJ09Lh6j5Aa4bKVXxCSDtxI8Y2jkwUhyaB4a9/cSHZ1stAjqSAo\npLmflhU0yBFM7UTQi5vJz2/QM8hgnGxdrgCXq2QQ0lx8bF0ubPWk/S6kGWsTdNFQXOw9/XFX\nwqtHmtMtqZ0sg3GxeYRUwiOSedrdDFzY+0BIyc/BLRDSDHzYe7cAH1eZ+1FsLyH5scAMnNhm\nx4njaj5PvXSfHsmTBSbg2zTDhOSrSzvNHQ3JxZcFxuPbMgipiZbkEssC9ji3zKh6I1QYNW0m\nlAU6IGuZwupjVAccqUNo00QkC3RA1TRybgs0s2pMLoEs0AEl27x5ikKiJ3KnVACE7PnuXoTU\nTEniILmYo2PQD+0gpFbG3WiHGt/RscWndqg+2hh3fxAe+kDHFF9JiPOuiWFCylkz7EelkCU4\n4gxASD05CFElS5CEDBjVI2UU0tGeY1gCCb7gEnU3wgspoU8FED69Oi0tupAyVhlwQLeD1UmP\n1ApCgnc6xoOLqV0zCCk339E9JR5ChF/3Hkm4HYCV9yuFZOPcGAHSOdAZZgizIZsqfxk5l/g4\nh9JRlv9P0C3vVBysVs4lPM5BSKr8ZpNr3ln9eGN1Q3icg5BEuTvmknO+ndv6aoRHAfRImtxF\ncK1DXlY6anI28VECUztJbEqFD+cqCIloeyBuCfHlVWBfKggIifrngbgl5n61ny0dvnlvdo9E\nR/5A3BI8Y/+Y2VM78fAZiLglEFIXEJI54pZASF1Q6ZHiNMD0SCkRmdqJx14l4qeC+PJ8omFS\n8WoI4AyN4EVI4ByN4EVI4ByR4I3VIyUkfd+lsv30jvANB2Hu3fcmy/FAaY6QepLmnEZICKkj\necIrz053Sb35ziQKrzS5d5fcu+9LIiGl6QZ3Sb79vnBO5wE/9yT9OZ0HHA1gAEICMAAhARiA\nkAAMQEgABgwSEuMrWNP6wB7FYBqzJC6owJrGqNAMpiErynSJH0ppjArRYEJIMAmEVP8mmnuH\nqdRExVtbJBpM9Egwi1dUnI0PPuJHM5iY2mVlyyWD3fR4uzNpfCUhyWASXBKMYOt5q5OewXpa\nrIlWcx9ory4Oaqfo1hPAZz0VHCFBKXJ1vSsh6ZlvjfjygqB3pCoJqUAnagl9jfr6YqAnJKUe\nyYNOTnG/ARcICklhahcJDDcEB0U+XALvjoGzPji4dwhkpOjg3REo9khgSg7nzi6sEFJ4Ujh3\n+tcPI6TwZHDutAuNb0tAR8HJ4F0BIU0vLqEzGdyrICQITorwWhYSAvQlRXxNHzZAeDLEF6Ud\ndCdDeCkJiRozKBncKiSk6GPwvOdEin3L9EjRL8xGPycOaNm2v2NHZcXBhRR8e4eEefayC4JH\nWvDtHVK/68zWukzsQyhoaBTVMwhpLCpFZh9CnhNlm3ItJG5YUKPAIX58dltpYbx77pGWs2mc\nH5/lQSZ6TrmvtJ+QVOJzObs+JDP1hieX65lhwfdYaUchzeLLhmdCEroOCw+uCmlcQnuutFeP\nNI3vBIOQHHJRSAMb9NdbdZrazWKti5MeCSFVM6BuupZSRk666lbqJ842dHEytaNHqmSIwS6J\ndejIuGqlfgKtIcFU+0xkjDKJ2Sm8xPqyQz/JRW3TdF6unHPkreQpbLKQCpt60bNOc1XbtCSY\nVTV4ECqzT+TZzN2/0IX+FtwuvIBf0XyGxmGsZBfS3Ix8KCTVPPRCfX0XuOsCIZUzM16PhCTb\nGb0QX94VqoU09ETWP2NHs68WD1Wf9uou8RBScY80MrodnLHD2bU+QhrJ2g2/oqmZ2o3DQ2jo\n4MFa2qurYPM7USVEs4WH0Nhkjkkd5G/x5RXjbFDgVUiz5nq6R+ID9fWV4kxIHs7YDbxZeSBR\njOLOxfpn7AburDyOQqPouz357T1jmCGkmtCbGKZlb+yhENHXegDGH1c1oTczTIve12trDOaM\nPq5qQm9qmCIkUAYhARgQS0i9ik8+eAdnhOqROkVwdef6/gNoKgmhpnZ93rp2lvr+A0y7QYoL\nD3S5qv4rQuLKIGjRHIvX61EDIVHegQitkWgxIdkpz/blsXxUdt8f2gOYx0whbUvm8PEkzx94\nPI8BJYEEU4W0+cKFBd9y+gx9gHFM7JF2XrdYHggJdJg4tdt52XJ5DBiBM86AMvTipEIe3cOc\nq1VeGX4CCoaJThYIVDzuP6FHxtqWPL5tb9zmIlrxxUVDxhHSbmqNmXPvozDbPv7kq08sX0yN\nq1ESRki7Gwmzw0/uQjKdLJ+osu5tPHxS9sX1KIlyXiMkq5fc/3vLFxPDIEp8ZeBdsgnpduIb\nhuty+mIIKQXJeqT7CWhWQC2P/JZTSGGjpJpl//7eIDl3G6PNPSvFpD1S8Cgph9R8jccQ0PXU\nLoUWOm8SIV2jpBJTt655daYozN6JHiFdpMBB4tY1DwHFtql/66m4a1ecH7/i5v0U0vVsInk2\nD5jhKObhWIjb9yPwDc7VrEKC3qi7b/nU0VURSArJ3TAU1sj77/PT5SYpSW/PVF66FPrGkQNt\nsgkxCzWUVgueokozm0BkivtX0cDczhs22YScBMU4F1LP3FP/2igvL76F1HO2Vv/aVJSZcd0j\nSQlJc2LeC7LvN56ndghpFmTfVjStNrtHej+FMgkp016NETVazwqj4AbEj2hKdEojpGYw2prv\ncMrTNyCkZuqNFj+sEodTouxrTLXVAt5g+X00JBZSgmOyE7VmG3XL/8iHza5Uw7kMtYgKaWAo\nb+UfzmWoRFNII4ur4/dCUlCEZo9U8bV9fd+LIg/K0JzaFQrJJswPXqV7ZrxqTBKmCqJ+KJKI\nVZgff416TyFdTe8kTBlU3VBy1PbvpDq/w9WGM/OcXg3PXmiMo5pyqO+Rj5Di4NoLTWFe90Nd\nmxCEFAffXqgK89s/lgo+eqQwBHFDgaLuQSclJKZ2YYjhh4KT+SEgLSFBFEJEVIk4nv9GsRwi\nsbjHswOf4VchpBsDFldDwDvq0+HYf6/UUlSu/f5zxXTEQ/Qj4Nd97+opuxFiWTQbJITUg8GF\nh1/3fX7jS+EzkxBSFkaXy37d1yIKTSHRI9kz/HBy7L+WfkeyR2JqZ4+FkOou9196q7m0hB8h\nmwMDIdXVCQf/kpgDv1wulyuluP8PcxTuSU+LBNu+fPeVkZByjJJEe6beJN12FQipAtEpXm+S\nbrsSox4plZAKHgceqRbyJ6Qp5jea2mXokR434BXdqRfHGO6E5CAWk0/tnjfgHceVu8g7QeNc\nKA4wD9WR9ur68+PMwUJSOKAk1lBsUoTkg7FCclCmDKHCpgjJCSN7JA9BMYSaw2nz8FHIqi+U\n1tJCmzVXX+Ryey7KwWuZeQ0h3anK8hvmF8vsQktpoS1TbP/UmA4cIT24Zm81O+qs5ITNlNDW\nu2z/1KjJnNhJOpFLWR4htbGfRLwJSay29wpCamInyl0KCUwQy+xCSzliL8ov9EibSnJiDvjX\nntn7VAROImc3XTRZ5fYYFPF5KvShUybzEjqm6YIqLi+9eis30WSaLqji0pJcSNZVF1VcVnIL\niQwCVmTukehpwI7EUzuEBOq4iE6EBOr4iM7G6667Ofz8bm+AKpyEUtNDVXfVd/sbJhhDCX5s\nxd3cfj14/xvBejFwsEU/thzv7STq/Ajp9c2DWvdhWqJj7U743drZEedGSE/5qH0ywBIZa/fC\n7dbKnljioEd6yQchOcbt1t48s1fj+ZjazRLS6K+GjK2jCEJy7qI3+YzskYZbTePY6obfzS1v\nOnKvpMe0YViwhXvk5WwcW+DuPvdCsonDyhcxfeTlYPtL6lZwSZX4F5IFtcFsaLXRDtAs5XdW\nJCn6HTQNO5b6YDZ8duxYIYkenDvzLuEx7FrjnlTfiYbosnt2LEL6tyMk5Qsa5J8tpkbXWJcg\nJBNEzTidSefLjAtymkcpQgrA75c8TflyyCm+kCzlvfVICGnNtCMaZ7xwN7XTTOxzuBdW08K5\n/Lus4+PPAnjtwf1MmS4kzrZ/HoUEd575YF6BVfhd1hnIvn/HPAN4UEbYKgXKvss6A7H2n6rs\ne7v/fcS2d+WKkH4Itf9kxfrQ7R7IJZnZt4lkgHRH48gEfPDJ/SVVIbBDJAukE9JI9r+hatbI\nUEu9Uou5CELqyY5gZhldrZ5UWstl1Iy7i9BpWr6U7X85SUhyh6bQUgwQCtAjhO7Aunz2IKQb\nQktJg9A9wRXxuPuspvMX6HC+xRGSk8NfiI8HqroT0sFTAs8ioUvFrVbGt65FqDpxwstiykI6\nyjuNkdspeYid5I2LEYoFJ7xbTOgU+jrYe9y+IFeFdQEhDeLDYkKn6cdSTp+X3vQOCOngxxBS\nJS4s1uc+ILV2pgsmPZLQAauLUD23y1HyuODkDPFhYRwPISKAh3BKkTy6YGA1F0ULlOFB7ZIg\nJAADEBKAARbxT48E6TERAIU1ZGLz6RUT1gHgmc0KDCEBVLE9E0BIAFUgpAzQrtZT+62hCCk+\n3JlQT/XQmR7pIvqnfY4brW1puAzK1O4SDi6XyQpJ+Awyup9Adn9yeLiBQ1VIyhXnkV8r9K+6\nPT08CEk0Ynvq+3qu2680amoQPaur4kJImjVURyFZnBy7z6mo8big2VVx0CNJsI7LfkLqWssi\npE5InvZybOWIbhUnQoKgbId2rzOo73SFHgmmMXhweJbrrimYqR3UY5M1Rk/gj1c9boqJkOCG\nVcwpTeAHqlplyzAZu5gTmskgJBiN6k0Rl0BIMJqQQqJHmotQcTIOpd7GjmGuNHybMOGX9BaG\nMP6bgp3twoSfj5vqQAuzeIkTfnF2AuNASCvi7ATGgZDWhClSr7c99E2l0CNtECV8Lg/iYk7y\nusDULi6XLw3FvLbUB6wUF4Q0EKwUF4Q0EKwUGHqkcWCmyDC1GwZ2AjAAIaWGjGMFdsxMWw+E\n+jbAJIlpm8oxgdgCi7QQ5ExuElLhDwUxUTG5dmtElLuhOgopXdpKtVkj4tyf2xLuRULKdyl3\nzl595/04QmpyRIn6ENKYN33F4aknBTUXSEhNFLgEIQ15z1cgnnYbku2I5KK0oEca8Z5PIZ2e\n7aKHv2CaVCObiRASgAFzeySENJVsWaMnk6d2PnukIKTrY3oy25Aep3ZBiDxZGx81Me0IBQQW\n0oRcG9KOUMJdSAEjYMYREdCMUMjvuR0xJyGkLtBl7fG/ZUIWdwipB8z9dgnbJdEj2cOVqANi\nJqR/TO06gJCOoOy1IrwdERKcYnCexI+wxh6Js/qEmQYyfm+LCjdBtDRZnRHFCTPbK+P3Npm5\nECybUBCeMHPgZ/3eCKkfCOkEhPT9IjZricaekOic7kQSEj1SN/7Xy7aOSFMPAvVITO168auX\nDdtS8L0RaGpngdyCBNjVC0KCPYiKNQgJqiEq1uzrhR4JdiAsNtjXi2BxDsa0+Zi42AK95KVx\nJEjAALzRepEKIQG8gZAADEBIABbs90iHnTNCAvhgTy/H1z4QEkAJJ1fjERJACQgJ3KJ0PQ8h\ngVd6fVRj+aX6p+iRwCW9Pjy4/D6p+fHC5ZJyPrVrOTuEKgJoppOQ7jq6v7JV1pOPuIYbrrlH\nOwYjhGT2HuoB1/ARID41FIU+PRJCKizZEJIANtW1bY3+eLX3HimlkApLNoQ0H8Wn87/W9D61\nS9gjFQuEHmk2it8Xs7cmo6yntdktPr4BvUwhTO0m40lIVi/f64XtoWRzA0KShpLNDdo9UpdX\n7/bKHaBkc4Oiq7quSW+7AA5BSAAGICQAAxASgAEICcAAhARgAEICMAAhARiAkAAMQEgABiAk\nAAMQEoABCAnAAIQEYABCAjAAIQEYgJAADEBIAAYgJAADEBKAAQgJwACEBGAAQgIwACEBGICQ\nAAxASAAGICQAAxASgAEICcAAhARgAEICMAAhARiAkAAMQEgABiAkAAOyCCnLPl3w7YwIzomw\nhxKy7NMlEZwTYQ8lZNmnSyI4x/celsdXvi+3///8/vGH338D83hzz90Zv556d879l25xvfh/\nL7fc/7/8+/jP29/MWyR8uufjl8/fP/+dUzyv/UsmH+74cAxCmsvy/v/lyx/fv3eK7w2UCOlW\nM/jep3fuVdtaSC/n+C7svAdYgZDeSzyYxmYp9+kc31JyvfgCIdEjqbCshfTtHM9O8rz2UiFR\n2k1ma9jw+POFYYMAb+74qB0+/4aMNJut8ff9z1+nHaUdQBGRgy3y3kCMyMEWeW8gRuRgi7w3\ngGEgJAADEBKAAQgJwACEBGAAQgIwACEBGICQAAxASAAGICQAAxASgAEICcAAhARgAEICMAAh\nARiAkAAMQEgABiAkAAMQEoABCAnAAIRUhPOHrgkTxbIxdtGb5e/fv1iqB8ufP3+2LOtOX86W\nO4cfHaGkHvzoaEtJe/rSxddqJ4GQerEjpD19CeNqsbNASL1ASLmgR+rFdg2HkKLirvd1w7Zl\n6ZEALHB3cjlbLoAmCAm8IJ2lhJcG8I5236S7MvDAuCwhPsmTXRh4YGCWQEgQlpHBjZBgC+nO\neYPN9Q4NbnqksFwQw7R7JRrXrHAHgvTZI7w0eS6IYdrde43Heu1d2tIx34Vs+zXkihhmCak1\nhez+XJQ7fC6TbLs23KIHIVm/i2dy7daGe0l3SQyTeqTmEK/KMQgJCngK6JIYJnURzUVXzXoR\nEhTwykQeW+oha6ZHgnP4vOw5Ho+Ya2TbrwV8XhZWEBAN5Dtv4QwiwgzkdUJoAwXe2mAo+E6I\nPYGIu7PBMII4IfhMPOzGRoOQTkBIITGv1xHSCcZCUmu4tFYzjA4NDT3SCaY9klzDJbWYYXRJ\nH2pnpByGBtKrE5XWMg7qMOcgJA1OhUR20QYhiXDS0NDvqEOPJMJhyqHy00etZtBajQhFQlLz\npD3xd2gIptqgREjxqz+56kkaLLXFuUriV396/bw0GGqT06rGlZCaajSEVAWGasOTkNpqNIRU\nBYZqxE+PdOURXD52qACWamVVL6kOudofwSW6IUkwlRWyKUq2Rgsl1EBbmYtw0yRao8mePE3E\n2ckM3s5UYSFpHv3KBmsgzEZm8H6mBouL/gQzWJiNTOD/UFheh32sSqU/CAnuLH8/xLNXQEkW\nVgIYnTwi5pVYhFOWsptbI527pphIQGWSorAGt5Te3IqSuiEz2xdYgl8Q0nQQki92qpCCsg0h\ndQUhuWJXMAVl/pnYRJplr9AjOeI9q9TH/fMnNn+UWcRFRO55xIcFvAnpGfcNgtqSDJWfNZNS\nFC4s4O3LLtu/P3ZbMgjJmFlNEy4sYXlPSD+/3Ij/sxSFkOporNAQkjQPr+4JaVlOU9SOZOiR\ntmm1C0LywfKq7N7utPv90xIlbU0bmNr98mmH9ky91SMNsDFOrOTuk19VPKRx9/rptVkks8/X\nMXOh5F2becT8Adc2sizLx+ShQEiwz6pWNuwdh1R7uL6dlZAwZjMr4Rj2jghJm7ebv2+FHrZs\nZ52B7OyJkKRZ3ucLRl53LsYry+85vaRHssU0TJe/9lnI+Sj82vJ7HiJM7SyxDdMOQnJ+cdb5\n8i+SZ98Hfm7RQ9Glo/qXdByJzpd/kTz73vdzmx5uT2wwT3K6kdh2D1QW8ux718979+6cfiGF\neeRI90hlX3Uju/zeJNr4np/37yat/fDr5ZZJeGpX9LF63eW/6LRIBzs34+Dz4qsQaXlAUOgT\nOUrh1msU7t8y19kSQFncfEgzSqhtE2R33S7OureMBRupqiFugoTaHjHyLUIajdVHYOPgogM6\nAyENp/6hGjHO7ODQI82mZIz30TId6y7E+e4RpnZzqS3cTnSXJHvlOS6y7PMylY87OdFd9H7q\nTpLj4ock27zOxgdmLiglh5By7PJGjl1a8K2b4yhBSP+y7PJGjl2a8FXJFUgle4+EkOCcsyhh\napfkuLiRZJvW/MggUZQ0Y3hciJ880ouT5aYhcdfGQv3YUl6bLBerOqhHvt0SXpou1+YMUMbh\nrfVyZ5XYcnxwafINZXweR19G1TurtFbjhSvXYqGIrWcYL3t/KYDUYvxweHfQ71PBMew1Dj/H\nj5AycHt+8exVeOdQKwgpAYJOdslp+axlYq3VRAAhGXE4mGNqF5rHDQ8IKR043JD7DQ/oKCF4\n3I7n942plR1GRN2XCZjmIm/R9fwGzJgZiUx7BJa5xnt0xRaSQe83J6WNedeAHh/JZ3Q9vuoF\nIe2+wnjDjPi6vn8I6RLPLzZ/nHmRP6Z0WUhzjpiTJ0KapauILh/F87vG9u9licTVE0JRSHbp\nKqbPh/Ac0kUt5r4p+Maoo38gKCTDBxgn8H8vnmVdFiGdcZay9HokhKTAQ0AI6ca5HeSmdghJ\ngscJG3W8cKM4+j0eKPRIEjxiLOp44YfyU8KjkJjawRhq1BE7M5+QduNQRFWaiZyZz8i7cyjB\nZb02A0wEh6Su1yrARnBM5nqtAowEcbgk+msnBkICL/T9NuyLl5QQEjjhVCb7g5GCZHP1JgeE\n9I82wAUFdyDt/YuSTIWQrsNgygPtQioa4SOkyzRdKiGJjabATTsnYpmD6ZGu0iIkkth4Cmy+\nfbwVOpip3UUahMT1/hk0R/qIY49gaLEzQvLFgEKcYPjXYOdtIdE3JQbXN7GVxOibeqN8Uumu\nTIWdBnb1p5R7vRl/UlUoF8efUOw9hNSZ8QaumYjj+GN+H4lf5D2E1JnhBq66Rovjj1nKv8iS\nHqkvCMkzVc8sEO6FIzD6pEJIhlCwCTH6pKJHssNUSKSskRhYm6mdHYb1hKcmyr/mB1vbu7n6\nY/cIQUdVoifNbzPa2r6t5QpHQtr9ZI+fPIWQwuJfSJ7yFEKKi5843Lkp189J8I8eKTJ+KqPN\nKPQlpMHWdmMWGMpWFDoT0lgwCxTjpzbdom+G8msXGI+f2nRN51PAr2EAKuhdlyIkeOI54ZyB\nkGAUvlugE0oei3fpEfztPwqxCD6UO390OE9aBQuCC+ks4Vx8ZnFcu0El0YV0AkICI0L3SKcg\nJLAi8tTuHHokAAuY2mUldwbRAk/4JXdPIwaOcEvyKZsY+MEtCEkJ/OCWVEKSbwfFlwcHJOqR\n9LeqvTo4RP6YtsJB8pVeHMAvYkLa/Bz+hHWANnqJTktIm7dAqCwOZJDqR+6iVlrT9k15KqsD\nFaRO/6eAWrJkp8yKkKAEJSFdWkuvLIaQBqHXYlQRRUj99kGPNASlcr4JoQ1oComp3QiUDvRG\nhFLqBVEPdoSMyaIQQEhKXBD12MyKx41BSDIMzax43BqhFgPGgcvNEWoxYBj4HIrgeDgG60AJ\n1x6xkwCMAwVcfOhbArANFKAtJIWyc/4KwAHSQuo4Jy2XqKhtQAzhHqnnvUDluxY1DqihUD5t\n0/fu1FIlqVoHDNEVgQUICcYQ/V6LbvtDSPDGtRPbQzbrtkZ6JHhx7WOmukOGETC1gyeXPh2n\nPPaWAhvF58qn4xBSIdgoAe09BEIqBRvBEcl7pHIwEhziYWqnAFYCMAAhARiAkAAMQEgABiAk\nAAMQEsA5p8NLhARGRB6Un19Oi7t3GEvkS7cFN3hE3Trs0idzhL6ZCCHBik4fg0NIkIpeH8wO\nLSR6JPim2xMOVrHmZvhQslCmdvBJx0eFfMaam+GDzUJdbBUMGfQoFDelntFCHewUbBlTciEk\nAAMQEoAF9EgAFoSa2p2/yPWXAACEBGAAQgIwACEBGICQAAzoLKTWgYibiQ/AL33jtXVE7+Ya\nBMCNruHaetHYzVXxPFAinICQ4tAx2KOXCNdNh5DC0PG27ugOMTgn6JGi0O+DRudCcl74WZwT\nTO2iMFFI3s89B0KCYfQU0rFU3Bd+CAne6PrR16MSwb2Q9HukOqjnrjHLfv6FpD61O37n77V7\nr7Tz4s9z9mfOtP2vn97k/1xLi7daooPyZxlgLRuEFA1ZefUINYQEndAt+GILSdjwMemcMIQP\nxkhC2pKNbCkQkt4PihQWUqQeCdlMpuv12983EBZSpKkdzKW7kJKV6nl2Ch/0F1KumiPRVuGD\nQQ/TzwKmTEuqhNEdbAlgwEQhcSJCHCaOv1MNdSA4Uy/IoiRXUEIcgJCgkIoSIqHkEBKUUeGw\njFU7PRKUUS6klGckU7vclDsBIR2SbLvwSc3tDcUlBEIa/ubkpLnU3XBX7K6MVfvM/Wa0txa9\n7lxNeELO7JEyVgBaDLgFPLQ0G28AAAa0SURBVAsIKTXcAm4FQsrN4RNU8xVo7dAjwQ5kqxqm\nPUXo57TjyBOmU/8U1eeTdvWdjKKa1zF9hBS2Chm5qZdavtujsOZ1TBchxe2LB+7pTS1f9oxr\nXs/06JHienrcnt5t+H9uWhCSOh3q7bietthTmcE/hPTzq2Xzr8A3J8HQu4if1mwbvG2hbd7U\nshIOPVIUTj3ZN9LnBdL1dy1OJ8tHQmJqF5HJtcXEt2990/0JXMHPUMpF5dOzFsdj1WtsBdag\nM7rxTfYncOU/jpDi8REM+3VW3ccJywNl4pcFtb1Hob0OXuBjagdhKDphyyOm9pSe94WqBkJq\nSZ4Ud1EpqPkrH6NSFSffsehKSDNeAOQxF1JLtyMupPpy7ssICCkBe0FS4/yvUrFNSbo9UvXp\nsFm7oqPg7AVJjfMvj3q1p3a177IxTWFqlxfpIq2NaUICZQSPOfEYQkiwRvLDsT26AbsDY5C5\naIk8MeXhQucx3eGryO3CcpS1BGsF2GOGkGYctZaFEuENKyYIaUrxn1lIZLYRjO+RENL2q/YK\nd3qtMQw/rxpi2mCN6j1St3Bn+heW+ntlLCKhQIyFeu0RlI9wf12UtjrfEFJcGu6VGREKpXrt\nKKTnErbW0qYthAR3BoVC+ee/+735YwmbH1tsNAI9EtzIIKT7B2APhNRuBaZ2cGPMmTpXSL/h\nvi+kZaFEg8uMOVNn9kjvS3goafn+c4QELpg4tXut4P5gho+1PDsodARx6JyRNuTymOmhIwhE\nz3C+zRy+FUN/BN2Ydz53fd9bcfctGkbY0ImJodX5bTfTD2UddGFmsdNbSDwJEoYhKCSrpLFs\ndUkAXdATklWtudyuGCGkdMw5PdV6JDNlL382XooMFZ9ZT08Rm9p1FdLu8zfRVximPD1lLn2F\n9G99V93ea1MCSmBznCGkx5+aRfXqQtLx/Q4m7wnNGJVkCOn5x3Z1Vtnj8xGSAmYCkHzCZCGN\nnzk1X8fpO+5WdghpNnaZxG/H23gGTNjuto3pkQRIWJJ902oCHaOtvmvN7ZnmmCElmbRn/Qvp\nCzLUFHbKBcvQ1/ZsNCHRMwlhmqfUPTuzR+qQqzcfPaRcEgTGtnNSF9LEqV2XL67ZfvSQsP3j\nkkxIbZjcB1RhmWK5b37rbEAHOMB4lnd2IPosPAYL6dOIhyZbTfEQ0iyMZ3nHSnFaeIwV0uc/\nrTMZQprHwCTh1c1je6QPK9WazOlRBVVkFlJd4/P8nopqk/ksnqGK1ELaeemNuL9lldd/PZoM\nuuK08Oi25J2nnrw/FfzNZCQbeOAzFnqt+f6A7+PPDb6+icznKQTwoFP4Ph7wXfYBXIo8mIlF\nDpwhpFUCQkgwEZPLZH2FtPfqZZ+aBRiAzY0bXXuk4xd/U1PFlSiXnSgIoy2k84j/EE+pPphK\ngDXiQtp7v/dBXbUoqAHBHuUeafftnjpASKCC8NRu791eQkBIEImxT7p4F0JTu0OPBJr0jsqv\nDyB93P3dklCZ2sE1OkVQ57D8/gASGQXm0uuBY4OF1PC1Y+QgsKPbIzBHC+n9d8tSoBJyGBji\nVUgbPdLHB81PVcKcDixxK6SvnPP63UNHJypBSGCKwx6p4GExCAlG425qd1K2FQqJHglccCVG\njx9LdyaSsh6JqV1cQnn2wlaOVXCebcqmdhAVz9/qt6Z9JydKobmBQ4J9qVk3IdHcwCEI6fGT\np00QZRvssykkvzHTrUcCOGajR3LcNtlN7fweJjCHVcR4rvbMVk1+gqsgJIZ0YABCQkhwQPm3\nlbjVkZWQFoQEe1TIw2+jbbPupexun9e/d2uvPJj5yHPBVo6ZkP5UGH5HdMhLCLsqCyFVvEpV\nYbfzr5n7CWEY/Qip5mWqCrtNIdFlKWEZ/Y5HCOWYTe0qyjKEpI9pGslQs0/Z4Wb+QkhSpEgj\nhsyx1eYRtZZXhpNMFhXjq6zjBKVFfpuM6QNUZsZ5qhMOVGo9qOzVdlXXX2DCcYqQoE5Iu/94\nQMMnHKcICWyENOJKlnKc0iNBVTJBSDs4GdhAT1dVXaHcr+xSCwm8oHLVaUd1mXokso9j5G+n\nyzO1ox/yjLyQ+iOyeSZ0rkFICAksUOmR5iGye4TknPQtrsr26ZHANTLBe/VIS38kZkPM4VKL\nuQAZLRlqXZnSWi5Aj5UMuTmh0FKugJCSgZD6gJCSgZA6QY+UDHqkTogNcaA3Yg6XWgyAVxAS\ngAEICcAAhARgAEICMAAhARiAkAAMQEgABiAkAAMQEoABCAnAAIQEYABCAjAAIQEYgJAADEBI\nAAYgJAADEBKAAf8BGCrQRAm4j5UAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df %>% ggplot() + \n",
    "    geom_point(aes(x = x, y = y, fill = class), shape = 21) + \n",
    "    facet_wrap(~ type) + \n",
    "    theme_void() +\n",
    "    labs(x = \"\", y = \"\") +\n",
    "    scale_fill_manual(values = c(\"red\", \"blue\")) + \n",
    "    guides(fill = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better adapt the *toy datasets* to the input/output format required by **CARET** we have prepared an alternative function to obtain these datasets, *get_partitioned_df*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'list'"
      ],
      "text/latex": [
       "'list'"
      ],
      "text/markdown": [
       "'list'"
      ],
      "text/plain": [
       "[1] \"list\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'normal'</li>\n",
       "\t<li>'circles'</li>\n",
       "\t<li>'spirals'</li>\n",
       "\t<li>'linear'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'normal'\n",
       "\\item 'circles'\n",
       "\\item 'spirals'\n",
       "\\item 'linear'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'normal'\n",
       "2. 'circles'\n",
       "3. 'spirals'\n",
       "4. 'linear'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"normal\"  \"circles\" \"spirals\" \"linear\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'list'"
      ],
      "text/latex": [
       "'list'"
      ],
      "text/markdown": [
       "'list'"
      ],
      "text/plain": [
       "[1] \"list\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'full'</li>\n",
       "\t<li>'full_train'</li>\n",
       "\t<li>'x_train'</li>\n",
       "\t<li>'y_train'</li>\n",
       "\t<li>'full_val'</li>\n",
       "\t<li>'x_val'</li>\n",
       "\t<li>'y_val'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'full'\n",
       "\\item 'full\\_train'\n",
       "\\item 'x\\_train'\n",
       "\\item 'y\\_train'\n",
       "\\item 'full\\_val'\n",
       "\\item 'x\\_val'\n",
       "\\item 'y\\_val'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'full'\n",
       "2. 'full_train'\n",
       "3. 'x_train'\n",
       "4. 'y_train'\n",
       "5. 'full_val'\n",
       "6. 'x_val'\n",
       "7. 'y_val'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"full\"       \"full_train\" \"x_train\"    \"y_train\"    \"full_val\"  \n",
       "[6] \"x_val\"      \"y_val\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partitioned_df <- get_partitioned_df()\n",
    "class(partitioned_df)\n",
    "names(partitioned_df)\n",
    "class(partitioned_df$normal)\n",
    "partitioned_df$normal %>% names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this function is a list with an item for each toy dataset. Each item contains the *full*  dataset and a partition of it in two subset: the *training* one (*_train*) and the *validation* one (*_val*). We'll see in the next lessons why we need to split a dataset in two partitions. \n",
    "\n",
    "For now, note that the *get_partitioned_df* provides, for both partitions, the input dataframe (*x_*) and the output dataframe (*y_*). These dataframes can be directly used with **CARET** training function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generalized Linear Model \n",
       "\n",
       "80 samples\n",
       " 2 predictor\n",
       " 2 classes: 'class_1', 'class_2' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 80, 80, 80, 80, 80, 80, ... \n",
       "Resampling results:\n",
       "\n",
       "  Accuracy  Kappa\n",
       "  1         1    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(x = partitioned_df$normal$x_train,\n",
    "      y = partitioned_df$normal$y_train$class, \n",
    "      method = \"glm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we used method **glm** (*Generalized Linear Model*) since we are trying to fit a classification problem while the *simpliest* **lm** method works only with regression problems (try to replace **glm** with **lm** in the cell above...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
