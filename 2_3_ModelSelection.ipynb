{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Now, we have a zoo of performance measures, we have discussed that we should avoid to optimize our models and its hyperparameters only on a subset of observations (i.e. the *training set*), but we should use the *testing set* only to asses the final performance of the *model*.\n",
    "\n",
    "In this notebook we'll see how to estimate the *test accuracy* (or any other model performance measure) leveraging only on the *training set* and, as a consequence, how to find a right **bias - variance tradeoff** while searching the right model and the right *hyper parameters*.\n",
    "\n",
    "### Validation Set Approach\n",
    "The first simple way to estimate the *test error* from the *training set* is to split it in two subsets:\n",
    "* The **real** *training set* on which the model is fitted.\n",
    "* A *validation set* used to estimate the *test error*\n",
    "\n",
    "Let's try this simple strategy on the titanic dataset, but first let's fit this dataset using **KKNN** with $k = 5$ on the whole *training set* and compute the *training error* and the *test error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.840958605664488"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.840958605664488"
      ],
      "text/markdown": [
       "**Accuracy:** 0.840958605664488"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.8409586 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.770408163265306"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.770408163265306"
      ],
      "text/markdown": [
       "**Accuracy:** 0.770408163265306"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.7704082 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source(\"src/lib.R\")\n",
    "source(\"src/titanic/titanic_dataset.R\")\n",
    "\n",
    "titanic_df <- get_titanic_df()\n",
    "\n",
    "model <-  train(\n",
    "    y = titanic_df$y_train$class,\n",
    "    x = titanic_df$x_train,\n",
    "    method = \"kknn\",\n",
    "    ks = 5,\n",
    "    trControl = trainControl(classProbs =  TRUE, method = \"none\"),\n",
    "    tuneGrid = data.frame(\n",
    "          kmax = 1,\n",
    "          distance = 2,\n",
    "          kernel = 'rectangular'\n",
    "      )\n",
    ")\n",
    "\n",
    "(full_train_error <- confusionMatrix(predict(model, titanic_df$x_train), titanic_df$y_train$class)$overall[\"Accuracy\"])\n",
    "(full_test_error <- confusionMatrix(predict(model, titanic_df$x_test), titanic_df$y_test$class)$overall[\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use **CARET** to directly estimate the *test error* using the *validation set* approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.856209150326797"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.856209150326797"
      ],
      "text/markdown": [
       "**Accuracy:** 0.856209150326797"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.8562092 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.782135076252723"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.782135076252723"
      ],
      "text/markdown": [
       "**Accuracy:** 0.782135076252723"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.7821351 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's split the training set in two partitions of equal size\n",
    "set.seed(29)\n",
    "full_indices <- 1:nrow(titanic_df$x_train)\n",
    "validation_set <- sample(full_indices, length(full_indices) / 2)\n",
    "small_train_set <- full_indices[!(full_indices %in% validation_set)]\n",
    "\n",
    "## Let's instruct CARET to use the small_train_set to estimate the accuracy and the validation_set to train it\n",
    "model <-  train(\n",
    "  y = titanic_df$y_train$class,\n",
    "  x = titanic_df$x_train,\n",
    "  method = \"kknn\",\n",
    "  ks = 5,\n",
    "  trControl = trainControl(\n",
    "    classProbs =  TRUE, \n",
    "    method = \"cv\",\n",
    "    index = list(sample = small_train_set),\n",
    "    indexOut = list(sample = validation_set),\n",
    "    indexFinal = small_train_set\n",
    "  ),\n",
    "  tuneGrid = data.frame(\n",
    "    kmax = 1,\n",
    "    distance = 2,\n",
    "    kernel = 'rectangular'\n",
    "  )\n",
    ")\n",
    "\n",
    "## Compute the accuracy on the small train set and on validation\n",
    "confusionMatrix(predict(model, titanic_df$x_train[small_train_set,]), titanic_df$y_train[small_train_set,]$class)$overall[\"Accuracy\"]\n",
    "confusionMatrix(predict(model, titanic_df$x_train[validation_set,]), titanic_df$y_train[validation_set,]$class)$overall[\"Accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! The estimation of our *testing error* is 0.79 nearer to the real value of 0.77 than 0.84. Note that this same measure can be directly extracted from the *train* function output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.793028322440087"
      ],
      "text/latex": [
       "0.793028322440087"
      ],
      "text/markdown": [
       "0.793028322440087"
      ],
      "text/plain": [
       "[1] 0.7930283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model$results$Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok...we have found a way to estimate the *testing error*...how good is this estimation varying $K$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df <- data_frame()\n",
    "for(k in seq(1,25)) {\n",
    "  model <-  train(\n",
    "    y = titanic_df$y_train$class,\n",
    "    x = titanic_df$x_train,\n",
    "    method = \"kknn\",\n",
    "    ks = k,\n",
    "    trControl = trainControl(\n",
    "      classProbs =  TRUE, \n",
    "      method = \"cv\",\n",
    "      index = list(sample = small_train_set),\n",
    "      indexOut = list(sample = validation_set)\n",
    "    ),\n",
    "    tuneGrid = data.frame(\n",
    "      kmax = 1,\n",
    "      distance = 2,\n",
    "      kernel = 'rectangular'\n",
    "    )\n",
    "  )\n",
    "  res_df <- rbind(\n",
    "    res_df,\n",
    "    data_frame(\n",
    "      k = k, \n",
    "      validation_error = model$results$Accuracy, \n",
    "      test_error = confusionMatrix(predict(model, titanic_df$x_test), titanic_df$y_test$class)$overall[\"Accuracy\"],\n",
    "      train_error = confusionMatrix(predict(model, titanic_df$x_train), titanic_df$y_train$class)$overall[\"Accuracy\"],\n",
    "    )\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFoCAMAAABJ+DwrAAAAP1BMVEUAujgBAgJNTU1OTk5h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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=3) ### set a small plot size\n",
    "\n",
    "res_df %>% gather(type, accuracy, -k) %>%\n",
    "  ggplot(aes(x = k, y = accuracy, color = type)) +\n",
    "  geom_line() + geom_point() + theme_few()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It really depends on the $k$ but the *validation set* error seldom overstimates the *testing error*.\n",
    "\n",
    "So...end of the story? Can we do any better?\n",
    "\n",
    "The *validation test* approach in *test error* estimation has two main drawbacks.\n",
    "\n",
    "* The *validation set error* is computed on a model fitted only on a part of the *training set* and, since a model fitted on more data should have lower *test error*, the *validation set error* may **overestimate** the *test error*\n",
    "* The *validation set error* strongly depends on the way in which the *validation set* is selected.\n",
    "\n",
    "On the second point, let's see what happens when we change the *validation set*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_res_df <- data_frame()\n",
    "for(attempt in 1:5) {  \n",
    "  validation_set <- sample(full_indices, length(full_indices) / 2)\n",
    "  small_train_set <- full_indices[!(full_indices %in% validation_set)]\n",
    "  for(k in seq(1,25,2)) {\n",
    "    model <-  train(\n",
    "      y = titanic_df$y_train$class,\n",
    "      x = titanic_df$x_train,\n",
    "      method = \"kknn\",\n",
    "      ks = k,\n",
    "      trControl = trainControl(\n",
    "        classProbs =  TRUE, \n",
    "        method = \"cv\",\n",
    "        index = list(sample = small_train_set),\n",
    "        indexOut = list(sample = validation_set)\n",
    "      ),\n",
    "      tuneGrid = data.frame(\n",
    "        kmax = 1,\n",
    "        distance = 2,\n",
    "        kernel = 'rectangular'\n",
    "      )\n",
    "    )\n",
    "    multi_res_df <- rbind(\n",
    "      multi_res_df,\n",
    "      data_frame(\n",
    "        k = k,\n",
    "        attempt = attempt,\n",
    "        accuracy = model$results$Accuracy, \n",
    "      )\n",
    "    )\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFoCAMAAABJ+DwrAAAAPFBMVEUAv8QBAgJNTU1OTk5p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\nTaqCQpOq+B+zkOteV5cwcAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_res_df %>% mutate(attempt = str_c(\"attempt_\", attempt)) %>%\n",
    "  rbind(res_df %>% select(k,accuracy = test_error) %>% mutate(attempt = \"test\")) %>%\n",
    "  mutate(type = ifelse(attempt == \"test\", \"test\", \"attempt\")) %>%\n",
    "  ggplot(aes(x = k, y = accuracy, color = type, group = attempt)) +\n",
    "  geom_line(size = 0.8) + theme_few()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation (aka CV) is a set of computing intensive techniques that allow to estimate the *test error* in more robust way w.r.t. the *validation set* approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave one out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Leave One Out Cross Validation* (aka LOOCV) estimation process is an iterative extension of the *validation set approach*:\n",
    "\n",
    "* From the training set $\\left\\{ (x_1,y_1), (x_2,y_2), \\dots, (x_n,y_n) \\right\\}$ set aside one single observation $(x_i,y_i)$.\n",
    "* Asses the performance of the model (with, as example, accuracy) using the left out observation $(x_i,y_i)$, and call this measure $A_i$\n",
    "* Iterate the process on all the *training set* observations, obtaining the set of performance measures $\\left\\{ A_1, A_2, \\dots, A_n \\right\\}$\n",
    "* Estimate the *test error* as:\n",
    "$$\\frac{1}{n} \\sum_{i = 1}^n A_i$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method solves the two main drawbacks of the *validation set* approach:\n",
    "\n",
    "* Each $A_i$ is compute on model fitted on almost all the *training set* observations.\n",
    "* There is no arbitrarity or randomness in the process\n",
    "\n",
    "Morever LOOCV is a built-in validation strategy in **CARET**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <-  train(\n",
    "  y = titanic_df$y_train$class,\n",
    "  x = titanic_df$x_train,\n",
    "  method = \"kknn\",\n",
    "  ks = 5,\n",
    "  trControl = trainControl(\n",
    "    classProbs =  TRUE, \n",
    "    method = \"LOOCV\"\n",
    "    #,verboseIter = T\n",
    "  ),\n",
    "  tuneGrid = data.frame(\n",
    "    kmax = 1,\n",
    "    distance = 2,\n",
    "    kernel = 'rectangular'\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.785403050108932"
      ],
      "text/latex": [
       "0.785403050108932"
      ],
      "text/markdown": [
       "0.785403050108932"
      ],
      "text/plain": [
       "[1] 0.7854031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.770408163265306"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.770408163265306"
      ],
      "text/markdown": [
       "**Accuracy:** 0.770408163265306"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.7704082 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model$results$Accuracy\n",
    "(full_test_error <- confusionMatrix(predict(model, titanic_df$x_test), titanic_df$y_test$class)$overall[\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any drawback?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:1:1: unexpected ')'\n1: )\n    ^\n",
     "execution_count": 8,
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:1:1: unexpected ')'\n1: )\n    ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
