{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "___\n",
    "\n",
    "*Source: [James et al., An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) *\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "Now, we have a zoo of performance measures, we have discussed that we should avoid to optimize our models and its hyperparameters only on a subset of observations (i.e. the *training set*), but we should use the *testing set* only to asses the final performance of the *model*.\n",
    "\n",
    "In this notebook we'll see how to estimate the *test accuracy* (or any other model performance measure) leveraging only on the *training set* and, as a consequence, how to find a right **bias - variance tradeoff** while searching the right model and the right *hyper parameters*.\n",
    "\n",
    "### Validation Set Approach\n",
    "The first simple way to estimate the *test error* from the *training set* is to split it in two subsets:\n",
    "* The **real** *training set* on which the model is fitted.\n",
    "* A *validation set* used to estimate the *test error*\n",
    "\n",
    "Let's try this simple strategy on the titanic dataset, but first let's fit this dataset using **KKNN** with $k = 5$ on the whole *training set* and compute the *training error* and the *test error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.840958605664488"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.840958605664488"
      ],
      "text/markdown": [
       "**Accuracy:** 0.840958605664488"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.8409586 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.770408163265306"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.770408163265306"
      ],
      "text/markdown": [
       "**Accuracy:** 0.770408163265306"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.7704082 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source(\"src/lib.R\")\n",
    "source(\"src/titanic/titanic_dataset.R\")\n",
    "\n",
    "titanic_df <- get_titanic_df()\n",
    "\n",
    "model <-  train(\n",
    "    y = titanic_df$y_train$class,\n",
    "    x = titanic_df$x_train,\n",
    "    method = \"kknn\",\n",
    "    ks = 5,\n",
    "    trControl = trainControl(classProbs =  TRUE, method = \"none\"),\n",
    "    tuneGrid = data.frame(\n",
    "          kmax = 1,\n",
    "          distance = 2,\n",
    "          kernel = 'rectangular'\n",
    "      )\n",
    ")\n",
    "\n",
    "(full_train_error <- confusionMatrix(predict(model, titanic_df$x_train), titanic_df$y_train$class)$overall[\"Accuracy\"])\n",
    "(full_test_error <- confusionMatrix(predict(model, titanic_df$x_test), titanic_df$y_test$class)$overall[\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use **CARET** to directly estimate the *test error* using the *validation set* approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.856209150326797"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.856209150326797"
      ],
      "text/markdown": [
       "**Accuracy:** 0.856209150326797"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.8562092 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.782135076252723"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.782135076252723"
      ],
      "text/markdown": [
       "**Accuracy:** 0.782135076252723"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.7821351 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's split the training set in two partitions of equal size\n",
    "set.seed(29)\n",
    "full_indices <- 1:nrow(titanic_df$x_train)\n",
    "validation_set <- sample(full_indices, length(full_indices) / 2)\n",
    "small_train_set <- full_indices[!(full_indices %in% validation_set)]\n",
    "\n",
    "## Let's instruct CARET to use the small_train_set to estimate the accuracy and the validation_set to train it\n",
    "model <-  train(\n",
    "  y = titanic_df$y_train$class,\n",
    "  x = titanic_df$x_train,\n",
    "  method = \"kknn\",\n",
    "  ks = 5,\n",
    "  trControl = trainControl(\n",
    "    classProbs =  TRUE, \n",
    "    method = \"cv\",\n",
    "    index = list(sample = small_train_set),\n",
    "    indexOut = list(sample = validation_set),\n",
    "    indexFinal = small_train_set\n",
    "  ),\n",
    "  tuneGrid = data.frame(\n",
    "    kmax = 1,\n",
    "    distance = 2,\n",
    "    kernel = 'rectangular'\n",
    "  )\n",
    ")\n",
    "\n",
    "## Compute the accuracy on the small train set and on validation\n",
    "confusionMatrix(predict(model, titanic_df$x_train[small_train_set,]), titanic_df$y_train[small_train_set,]$class)$overall[\"Accuracy\"]\n",
    "confusionMatrix(predict(model, titanic_df$x_train[validation_set,]), titanic_df$y_train[validation_set,]$class)$overall[\"Accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! The estimation of our *testing error* is 0.79 nearer to the real value of 0.77 than 0.84. Note that this same measure can be directly extracted from the *train* function output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.782135076252723"
      ],
      "text/latex": [
       "0.782135076252723"
      ],
      "text/markdown": [
       "0.782135076252723"
      ],
      "text/plain": [
       "[1] 0.7821351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model$results$Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok...we have found a way to estimate the *testing error*...how good is this estimation varying $K$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df <- data_frame()\n",
    "for(k in seq(1,25)) {\n",
    "  model <-  train(\n",
    "    y = titanic_df$y_train$class,\n",
    "    x = titanic_df$x_train,\n",
    "    method = \"kknn\",\n",
    "    ks = k,\n",
    "    trControl = trainControl(\n",
    "      classProbs =  TRUE, \n",
    "      method = \"cv\",\n",
    "      index = list(sample = small_train_set),\n",
    "      indexOut = list(sample = validation_set)\n",
    "    ),\n",
    "    tuneGrid = data.frame(\n",
    "      kmax = 1,\n",
    "      distance = 2,\n",
    "      kernel = 'rectangular'\n",
    "    )\n",
    "  )\n",
    "  res_df <- rbind(\n",
    "    res_df,\n",
    "    data_frame(\n",
    "      k = k, \n",
    "      validation_error = model$results$Accuracy, \n",
    "      test_error = confusionMatrix(predict(model, titanic_df$x_test), titanic_df$y_test$class)$overall[\"Accuracy\"],\n",
    "      train_error = confusionMatrix(predict(model, titanic_df$x_train), titanic_df$y_train$class)$overall[\"Accuracy\"],\n",
    "    )\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFoCAMAAABJ+DwrAAAAP1BMVEUAujgBAgJNTU1OTk5h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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=3) ### set a small plot size\n",
    "\n",
    "res_df %>% gather(type, accuracy, -k) %>%\n",
    "  ggplot(aes(x = k, y = accuracy, color = type)) +\n",
    "  geom_line() + geom_point() + theme_few()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It really depends on the $k$ but the *validation set* error sometimes overstimates the *testing error* (or understimate the accuracy).\n",
    "\n",
    "So...end of the story? Can we do any better?\n",
    "\n",
    "The *validation test* approach in *test error* estimation has two main drawbacks.\n",
    "\n",
    "* The *validation set error* is computed on a model fitted only on a part of the *training set* and, since a model fitted on more data should have lower *test error*, the *validation set error* may **overestimate** the *test error*\n",
    "* The *validation set error* strongly depends on the way in which the *validation set* is selected.\n",
    "\n",
    "On the second point, let's see what happens when we change the *validation set*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_res_df <- data_frame()\n",
    "for(attempt in 1:10) {  \n",
    "  validation_set <- sample(full_indices, length(full_indices) / 2)\n",
    "  small_train_set <- full_indices[!(full_indices %in% validation_set)]\n",
    "  for(k in seq(1,25,2)) {\n",
    "    model <-  train(\n",
    "      y = titanic_df$y_train$class,\n",
    "      x = titanic_df$x_train,\n",
    "      method = \"kknn\",\n",
    "      ks = k,\n",
    "      trControl = trainControl(\n",
    "        classProbs =  TRUE, \n",
    "        method = \"cv\",\n",
    "        index = list(sample = small_train_set),\n",
    "        indexOut = list(sample = validation_set)\n",
    "      ),\n",
    "      tuneGrid = data.frame(\n",
    "        kmax = 1,\n",
    "        distance = 2,\n",
    "        kernel = 'rectangular'\n",
    "      )\n",
    "    )\n",
    "    multi_res_df <- rbind(\n",
    "      multi_res_df,\n",
    "      data_frame(\n",
    "        k = k,\n",
    "        attempt = attempt,\n",
    "        accuracy = model$results$Accuracy, \n",
    "      )\n",
    "    )\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFoCAMAAABJ+DwrAAAAPFBMVEUAv8QBAgJNTU1OTk5p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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_res_df %>% mutate(attempt = str_c(\"attempt_\", attempt)) %>%\n",
    "  rbind(res_df %>% select(k,accuracy = test_error) %>% mutate(attempt = \"test\")) %>%\n",
    "  mutate(type = ifelse(attempt == \"test\", \"test\", \"attempt\")) %>%\n",
    "  ggplot(aes(x = k, y = accuracy, color = type, group = attempt)) +\n",
    "  geom_line(size = 0.8) + theme_few()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation (aka CV) is a set of computing intensive techniques that allow to estimate the *test error* in more robust way w.r.t. the *validation set* approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave one out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Leave One Out Cross Validation* (aka LOOCV) estimation process is an iterative extension of the *validation set approach*:\n",
    "\n",
    "* From the training set $\\left\\{ (x_1,y_1), (x_2,y_2), \\dots, (x_n,y_n) \\right\\}$ set aside one single observation $(x_i,y_i)$.\n",
    "* Asses the performance of the model (with, as example, accuracy) using the left out observation $(x_i,y_i)$, and call this measure $A_i$\n",
    "* Iterate the process on all the *training set* observations, obtaining the set of performance measures $\\left\\{ A_1, A_2, \\dots, A_n \\right\\}$\n",
    "* Estimate the *test error* as:\n",
    "$$\\frac{1}{n} \\sum_{i = 1}^n A_i$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method solves the two main drawbacks of the *validation set* approach:\n",
    "\n",
    "* Each $A_i$ is compute on model fitted on almost all the *training set* observations.\n",
    "* There is no arbitrarity or randomness in the process\n",
    "\n",
    "Morever LOOCV is a built-in validation strategy in **CARET**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  57.00    0.00   57.02 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time(\n",
    "model <-  train(\n",
    "  y = titanic_df$y_train$class,\n",
    "  x = titanic_df$x_train,\n",
    "  method = \"kknn\",\n",
    "  ks = 5,\n",
    "  trControl = trainControl(\n",
    "    classProbs =  TRUE, \n",
    "    method = \"LOOCV\"\n",
    "    #,verboseIter = T\n",
    "  ),\n",
    "  tuneGrid = data.frame(\n",
    "    kmax = 1,\n",
    "    distance = 2,\n",
    "    kernel = 'rectangular'\n",
    "  )\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.785403050108932"
      ],
      "text/latex": [
       "0.785403050108932"
      ],
      "text/markdown": [
       "0.785403050108932"
      ],
      "text/plain": [
       "[1] 0.7854031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.770408163265306"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.770408163265306"
      ],
      "text/markdown": [
       "**Accuracy:** 0.770408163265306"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.7704082 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model$results$Accuracy\n",
    "(full_test_error <- confusionMatrix(predict(model, titanic_df$x_test), titanic_df$y_test$class)$overall[\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any drawback? \n",
    "\n",
    "The **computational requirements**: we need to fit $n$ models where $n$ is the set of observations in the *training set*!\n",
    "\n",
    "On small datasets this is not a problem....but we want to work with **BIG DATA!**\n",
    "\n",
    "P.S. there are some models in which the *LOOCV test error estimation* can be efficiently computed (i.e. *Linear Regression*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to maintain the benefits of *LOOCV* but with less computational burden we can use the *K-Fold validation* approach:\n",
    "* **Randomly** split the *training set* in $k$ equal (or almost equal) parts.\n",
    "  $$\\left\\{ F_1,\\dots,F_k \\right\\}$$\n",
    "* For each fold $F_i$, fit the model on all the points in the *training set* with the exception of the points in $F_i$ and Compute the *accuracy* of the fitted model on $F_i$ and call it $A_i.\n",
    "* Estimate the *testing error* as:\n",
    "    $$\\frac{1}{k} \\sum_{i=1}^k A_i$$\n",
    "\n",
    "Here we are reintroducing the *randomness* in the process but averaging *k* attempts we will significatly reduce the variability in the estimation process. Note that when $k=n$ we go back to the *LOOCV*.\n",
    "\n",
    "Let's this in practice with **CARET** (here a way to do a *10-fold* cross validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "   1.23    0.00    1.24 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.782166746297181"
      ],
      "text/latex": [
       "0.782166746297181"
      ],
      "text/markdown": [
       "0.782166746297181"
      ],
      "text/plain": [
       "[1] 0.7821667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time(\n",
    "model <-  train(\n",
    "  y = titanic_df$y_train$class,\n",
    "  x = titanic_df$x_train,\n",
    "  method = \"kknn\",\n",
    "  ks = 5,\n",
    "  trControl = trainControl(\n",
    "    classProbs =  TRUE, \n",
    "    method = \"cv\",\n",
    "    number = 10\n",
    "    #,verboseIter = T\n",
    "  ),\n",
    "  tuneGrid = data.frame(\n",
    "    kmax = 1,\n",
    "    distance = 2,\n",
    "    kernel = 'rectangular'\n",
    "  )\n",
    ")\n",
    ")\n",
    "\n",
    "model$results$Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...a similar accuracy estimation but a fraction (1s vs. 60s on my machin) of the computational effort. Let's what happens we a repeated estimation procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_res_df <- data_frame()\n",
    "for(attempt in 1:10) {  \n",
    "  validation_set <- sample(full_indices, length(full_indices) / 2)\n",
    "  small_train_set <- full_indices[!(full_indices %in% validation_set)]\n",
    "  for(k in seq(1,25,2)) {\n",
    "    model <-  train(\n",
    "      y = titanic_df$y_train$class,\n",
    "      x = titanic_df$x_train,\n",
    "      method = \"kknn\",\n",
    "      ks = k,\n",
    "      trControl = trainControl(\n",
    "        classProbs =  TRUE, \n",
    "        method = \"cv\",\n",
    "        number = 10\n",
    "      ),\n",
    "      tuneGrid = data.frame(\n",
    "        kmax = 1,\n",
    "        distance = 2,\n",
    "        kernel = 'rectangular'\n",
    "      )\n",
    "    )\n",
    "    k_fold_res_df <- rbind(\n",
    "      k_fold_res_df,\n",
    "      data_frame(\n",
    "        k = k,\n",
    "        attempt = attempt,\n",
    "        accuracy = model$results$Accuracy, \n",
    "      )\n",
    "    )\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFoCAMAAABJ+DwrAAAAP1BMVEUAujgBAgJNTU1OTk5h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\nKCA0EAWEBqKA0EAU/wOkzT+IjdswYQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_res_df %>% mutate(attempt = str_c(\"VS \", attempt)) %>%\n",
    "  rbind(res_df %>% select(k,accuracy = test_error) %>% mutate(attempt = \"test\")) %>%\n",
    "  mutate(type = ifelse(attempt == \"test\", \"test\", \"validation set approach\")) %>%\n",
    "  rbind(k_fold_res_df %>% mutate(type = \"10-Fold\") %>% mutate(attempt = str_c(\"KF \", attempt))) %>%\n",
    "  ggplot(aes(x = k, y = accuracy, color = type, group = attempt)) +\n",
    "  geom_line(size = 0.8) + theme_few()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage of the *K-Fold validation* w.r.t. to the *LOOCV* is linked with the *Bias-Variance tradeoff*, using the *LOOCV* we fit *n* models on almost identical dataset and as a consequence the fitted models are highly positive correlated. As a consequence the *test error* estimation derived from *LOOCV* has a high *variance* w.r.t. the one derived from the *K-Fold validation* when K is small enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>kmax</th><th scope=col>distance</th><th scope=col>kernel</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1          </td><td>2          </td><td>rectangular</td><td>0.792893   </td><td>0.5626414  </td><td>0.05663257 </td><td>0.1112675  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " kmax & distance & kernel & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "\\hline\n",
       "\t 1           & 2           & rectangular & 0.792893    & 0.5626414   & 0.05663257  & 0.1112675  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "kmax | distance | kernel | Accuracy | Kappa | AccuracySD | KappaSD | \n",
       "|---|\n",
       "| 1           | 2           | rectangular | 0.792893    | 0.5626414   | 0.05663257  | 0.1112675   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  kmax distance kernel      Accuracy Kappa     AccuracySD KappaSD  \n",
       "1 1    2        rectangular 0.792893 0.5626414 0.05663257 0.1112675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model$results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
