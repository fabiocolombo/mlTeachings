{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to.\n",
    "\n",
    "#### And a little bit of math.\n",
    "\n",
    "The basic of neural network\n",
    "\n",
    "___\n",
    "\n",
    "*Source: [Chollet et al., Deep Learning With R](https://www.amazon.com/Deep-Learning-R-Francois-Chollet/dp/161729554X) *\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that a neural networks is composed of\n",
    "- Some Layers (and weights)\n",
    "- A loss function\n",
    "- A looping function (the optimization algorith)\n",
    "- **Lots** of other stuffs, but the ones above here are the most important.\n",
    "\n",
    "___\n",
    "\n",
    "## MNIST: the *Hello world!* of deep learning\n",
    "\n",
    "You can istantiate your basic nnet in keras by simply knowing these easy concepts, but let's dive a little bit deeper in the **workflow** of creating and training a neural network, starting from the MNIST example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "source('src/lib.R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = dataset_mnist()\n",
    "train_images = mnist$train$x\n",
    "train_labels = mnist$train$y\n",
    "test_images = mnist$test$x\n",
    "test_labels = mnist$test$y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{train}$\\_$\\texttt{images}$ and $\\texttt{train}$\\_$\\texttt{labels}$ form the training set , the data that the model will learn from. The model will then be tested on the test set $\\texttt{test}$\\_$\\texttt{images}$ and $\\texttt{test}$\\_$\\texttt{labels}$. The images are encoded as as 3D arrays, and the labels are a 1D array of digits, ranging from 0 to 9. There is a one-to-one correspondence between the images and the labels.\n",
    "\n",
    "Let's have a look at the structure of the data (with the $\\texttt{str}$ function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "train_images %>% str\n",
    "# 3d array\n",
    "# 60,000 images, 28x28 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ...\n"
     ]
    }
   ],
   "source": [
    "train_labels %>% str\n",
    "# 1d array\n",
    "# 60,000 image labes scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n",
      " int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ...\n"
     ]
    }
   ],
   "source": [
    "test_images %>% str\n",
    "test_labels%>% str\n",
    "# the validation set is composed of 10,000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the network\n",
    "\n",
    "The core building block of neural networks is the **layer**, a data-processing module that you can think of as a filter for data. Some data comes in, and it comes out in a more useful form. Specifically, layers extract representations out of the data fed into them, that are - hopefully - more meaningful for the problem at hand.\n",
    "\n",
    "Most of deep learning consists of **chaining together** simple layers that will implement a form of progressive data distillation (the **%>%** operator is very practical here!!!). \n",
    "\n",
    "> In the coming code snippets there may be a few parameter you cannot make your mind around. We will eventually explain them, don't you worry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = keras_model_sequential() %>% # keras_model_sequential is the basic call to start building the nnet\n",
    "            # first layer\n",
    "            layer_dense(units = 512,\n",
    "                        activation = \"relu\",\n",
    "                        input_shape = c(28 * 28),\n",
    "                        use_bias = T,\n",
    "                        name='first_layer'\n",
    "                       ) %>%\n",
    "            # second layer\n",
    "            layer_dense(units = 10,\n",
    "                        activation = \"softmax\",\n",
    "                        use_bias = T,\n",
    "                        name = 'output_layer'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our network consists of a sequence of **two** layers, which are densely connected (also called **fully connected**) neural layers. The second (and last) layer is a 10-way **softmax** layer, which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes. \n",
    "\n",
    "Here below you can se what you just did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "________________________________________________________________________________\n",
       "Layer (type)                        Output Shape                    Param #     \n",
       "================================================================================\n",
       "first_layer (Dense)                 (None, 512)                     401920      \n",
       "________________________________________________________________________________\n",
       "output_layer (Dense)                (None, 10)                      5130        \n",
       "================================================================================\n",
       "Total params: 407,050\n",
       "Trainable params: 407,050\n",
       "Non-trainable params: 0\n",
       "________________________________________________________________________________\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Istantiate the network\n",
    "\n",
    "Up to this point, you have't technically creating anything: the $\\texttt{network}$ object is just a pipeline of information that needs to be istantiated in a c++ TensorFlow structure to be efficiently used. The **process of making the network ready for training** is performed through the call to the **keras** method (function) $\\texttt{compile}$\n",
    "\n",
    "As part of the *compilation* step, we must define:\n",
    "- A **loss function**: how the network will be able to measure how good a job it’s doing on its training data, and thus how it will be able to steer itself in the right direction.\n",
    "- An **optimizer**: the mechanism (algorithm) through which the network will update itself based on the data it sees and its loss function.\n",
    "- The **metric(s)** to monitor during training and testing. Here we’ll only care about accuracy (the fraction of the images that were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that the compile function does not create any new R object, rather it modifies the existing one (network, in this case)\n",
    "\n",
    "network %>% compile(optimizer = \"rmsprop\",\n",
    "                    loss = \"categorical_crossentropy\",\n",
    "                    metrics = c(\"accuracy\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you get used to the most basic things, you can access and manipulate the network object as a standard $\\texttt{R}$ list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'add, add_loss, add_update, add_weight, assert_input_compatibility, build, built, call, compile, compute_mask, compute_output_shape, count_params, evaluate, evaluate_generator, fit, fit_generator, from_config, get_config, get_input_at, get_input_mask_at, get_input_shape_at, get_layer, get_losses_for, get_output_at, get_output_mask_at, get_output_shape_at, get_updates_for, get_weights, input, input_layers, input_layers_node_indices, input_layers_tensor_indices, input_mask, input_names, input_shape, input_spec, inputs, layers, legacy_from_config, legacy_get_config, load_weights, loss, loss_weights, losses, metrics, metrics_names, metrics_tensors, model, name, non_trainable_weights, optimizer, output, output_layers, output_layers_node_indices, output_layers_tensor_indices, output_mask, output_names, output_shape, outputs, pop, predict, predict_classes, predict_generator, predict_on_batch, predict_proba, regularizers, reset_states, run_internal_graph, sample_weight_mode, sample_weights, save, save_weights, set_weights, state_updates, stateful, summary, supports_masking, targets, test_on_batch, to_json, to_yaml, total_loss, train_on_batch, trainable, trainable_weights, updates, uses_learning_phase, weighted_metrics, weights'"
      ],
      "text/latex": [
       "'add, add\\_loss, add\\_update, add\\_weight, assert\\_input\\_compatibility, build, built, call, compile, compute\\_mask, compute\\_output\\_shape, count\\_params, evaluate, evaluate\\_generator, fit, fit\\_generator, from\\_config, get\\_config, get\\_input\\_at, get\\_input\\_mask\\_at, get\\_input\\_shape\\_at, get\\_layer, get\\_losses\\_for, get\\_output\\_at, get\\_output\\_mask\\_at, get\\_output\\_shape\\_at, get\\_updates\\_for, get\\_weights, input, input\\_layers, input\\_layers\\_node\\_indices, input\\_layers\\_tensor\\_indices, input\\_mask, input\\_names, input\\_shape, input\\_spec, inputs, layers, legacy\\_from\\_config, legacy\\_get\\_config, load\\_weights, loss, loss\\_weights, losses, metrics, metrics\\_names, metrics\\_tensors, model, name, non\\_trainable\\_weights, optimizer, output, output\\_layers, output\\_layers\\_node\\_indices, output\\_layers\\_tensor\\_indices, output\\_mask, output\\_names, output\\_shape, outputs, pop, predict, predict\\_classes, predict\\_generator, predict\\_on\\_batch, predict\\_proba, regularizers, reset\\_states, run\\_internal\\_graph, sample\\_weight\\_mode, sample\\_weights, save, save\\_weights, set\\_weights, state\\_updates, stateful, summary, supports\\_masking, targets, test\\_on\\_batch, to\\_json, to\\_yaml, total\\_loss, train\\_on\\_batch, trainable, trainable\\_weights, updates, uses\\_learning\\_phase, weighted\\_metrics, weights'"
      ],
      "text/markdown": [
       "'add, add_loss, add_update, add_weight, assert_input_compatibility, build, built, call, compile, compute_mask, compute_output_shape, count_params, evaluate, evaluate_generator, fit, fit_generator, from_config, get_config, get_input_at, get_input_mask_at, get_input_shape_at, get_layer, get_losses_for, get_output_at, get_output_mask_at, get_output_shape_at, get_updates_for, get_weights, input, input_layers, input_layers_node_indices, input_layers_tensor_indices, input_mask, input_names, input_shape, input_spec, inputs, layers, legacy_from_config, legacy_get_config, load_weights, loss, loss_weights, losses, metrics, metrics_names, metrics_tensors, model, name, non_trainable_weights, optimizer, output, output_layers, output_layers_node_indices, output_layers_tensor_indices, output_mask, output_names, output_shape, outputs, pop, predict, predict_classes, predict_generator, predict_on_batch, predict_proba, regularizers, reset_states, run_internal_graph, sample_weight_mode, sample_weights, save, save_weights, set_weights, state_updates, stateful, summary, supports_masking, targets, test_on_batch, to_json, to_yaml, total_loss, train_on_batch, trainable, trainable_weights, updates, uses_learning_phase, weighted_metrics, weights'"
      ],
      "text/plain": [
       "[1] \"add, add_loss, add_update, add_weight, assert_input_compatibility, build, built, call, compile, compute_mask, compute_output_shape, count_params, evaluate, evaluate_generator, fit, fit_generator, from_config, get_config, get_input_at, get_input_mask_at, get_input_shape_at, get_layer, get_losses_for, get_output_at, get_output_mask_at, get_output_shape_at, get_updates_for, get_weights, input, input_layers, input_layers_node_indices, input_layers_tensor_indices, input_mask, input_names, input_shape, input_spec, inputs, layers, legacy_from_config, legacy_get_config, load_weights, loss, loss_weights, losses, metrics, metrics_names, metrics_tensors, model, name, non_trainable_weights, optimizer, output, output_layers, output_layers_node_indices, output_layers_tensor_indices, output_mask, output_names, output_shape, outputs, pop, predict, predict_classes, predict_generator, predict_on_batch, predict_proba, regularizers, reset_states, run_internal_graph, sample_weight_mode, sample_weights, save, save_weights, set_weights, state_updates, stateful, summary, supports_masking, targets, test_on_batch, to_json, to_yaml, total_loss, train_on_batch, trainable, trainable_weights, updates, uses_learning_phase, weighted_metrics, weights\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network %>% names %>% paste(collapse = \", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data\n",
    "Before training, we’ll preprocess the data by **reshaping** it into the shape the network expects and scaling it so that all values have a value in the $[0, 1]$. Indeed, our training images were previously stored in an array of shape (60,000, 28, 28) **of type integer** with values in the $[0, 255]$ interval. Now they will be stored in a two dimensional array of shape (60,000, **784**) **of type numeric** (alias float, double), bounded between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:60000, 1:784] 0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "(train_images = array_reshape(train_images, c(60000, 28 * 28)) / 255) %>% str\n",
    "test_images = array_reshape(test_images, c(10000, 28 * 28)) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need co **categorically encode** the labels. *One-hot econding* basically means to create an ordered vector which is biunivocally related to the another space (i.e. the output space, in our case). The one-hot vector has value 1 wherever it matches an object in the output space, and zero elsewere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:60000, 1:10] 0 1 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "# now the labels are a 2d tensor, with 10 one-hot encoded values per observation.\n",
    "(train_labels = to_categorical(train_labels)) %>% str\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the newtork\n",
    "\n",
    "We are now ready to train the network, which in **keras** is done via the call to the network's $\\texttt{fit}$ method (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "network %>% fit(train_images,\n",
    "                train_labels,\n",
    "                epochs = 5,\n",
    "                batch_size = 128\n",
    "                ) -> history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{Epoch 1/5 60000/60000 [==============================] - 9s - loss: 0.2575 - acc: 0.9255}$\n",
    "$\\texttt{Epoch 2/5 60000/60000 [==============================] - 10s - loss: 0.1038 - acc: 0.9687}$\n",
    "$\\texttt{Epoch 3/5 60000/60000 [==============================] - 10s - loss: 0.0688 - acc: 0.9793}$\n",
    "$\\texttt{Epoch 4/5 60000/60000 [==============================] - 9s - loss: 0.0496 - acc: 0.9855}$\n",
    "$\\texttt{Epoch 5/5 60000/60000 [==============================] - 9s - loss: 0.0372 - acc: 0.988}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are displayed during training: the of the network over the trainingloss data, and the accuracy of the network over the training data.\n",
    "\n",
    "The test-set accuracy turns out to be that quite a bit lower than the training set accuracy. This gap between training accuracy and test accuracy is an example of overfitting : the fact that machine-learning models tend to perform worse on new data than on their training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$loss</dt>\n",
       "\t\t<dd>0.219335038348251</dd>\n",
       "\t<dt>$acc</dt>\n",
       "\t\t<dd>0.963</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$loss] 0.219335038348251\n",
       "\\item[\\$acc] 0.963\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$loss\n",
       ":   0.219335038348251\n",
       "$acc\n",
       ":   0.963\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$loss\n",
       "[1] 0.219335\n",
       "\n",
       "$acc\n",
       "[1] 0.963\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(metrics = network %>% evaluate(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'params'</li>\n",
       "\t<li>'metrics'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'params'\n",
       "\\item 'metrics'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'params'\n",
       "2. 'metrics'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"params\"  \"metrics\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history %>% names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s generate predictions for the first 10 samples of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'7, 2, 1, 0, 4, 1, 4, 9, 6, 9'"
      ],
      "text/latex": [
       "'7, 2, 1, 0, 4, 1, 4, 9, 6, 9'"
      ],
      "text/markdown": [
       "'7, 2, 1, 0, 4, 1, 4, 9, 6, 9'"
      ],
      "text/plain": [
       "[1] \"7, 2, 1, 0, 4, 1, 4, 9, 6, 9\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network %>% predict_classes(test_images[1:10,]) %>% paste(collapse = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Data representation for neural networks\n",
    "\n",
    "Data representations for neural networks In the previous example, we started from data stored in multidimensional arrays, also called tensors . In general, all current machine-learning systems use tensors as their basic data structure. **Tensors are fundamental** to the field, so fundamental that Google’s TensorFlow was named after them. So what’s a tensor?\n",
    " \n",
    "Tensors are a generalization of vectors and matrices to an arbitrary number of dimensions (note that in the context of tensors, \"dimension\" is often called \"axis\"). Within $\\texttt{R}$, vectors ($\\texttt{vector}$) are used to create and manipulate 1D tensors and matrices ($\\texttt{matrix}$) are used for 2D tensors. For higher level dimensions dimensions) $\\texttt{array}$ objects (which support any number of dimensions) are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:5] 12 3 6 14 10\n",
      "[1] 12  3  6 14 10\n",
      "[1] 5\n"
     ]
    }
   ],
   "source": [
    "# a vector\n",
    "\n",
    "(x = c(12, 3, 6, 14, 10) ) %>% str\n",
    "x %>% print\n",
    "x %>% as.array %>% dim %>% print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:3, 1:5] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "     [,1] [,2] [,3] [,4] [,5]\n",
      "[1,]    0    0    0    0    0\n",
      "[2,]    0    0    0    0    0\n",
      "[3,]    0    0    0    0    0\n",
      "[1] 3 5\n"
     ]
    }
   ],
   "source": [
    "# a matrix\n",
    "\n",
    "(x = matrix(rep(0, 3*5), nrow = 3, ncol = 5)) %>% str\n",
    "x %>% print\n",
    "x %>% dim %>% print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:2, 1:3, 1:2] 0 0 0 0 0 0 0 0 0 0 ...\n",
      ", , 1\n",
      "\n",
      "     [,1] [,2] [,3]\n",
      "[1,]    0    0    0\n",
      "[2,]    0    0    0\n",
      "\n",
      ", , 2\n",
      "\n",
      "     [,1] [,2] [,3]\n",
      "[1,]    0    0    0\n",
      "[2,]    0    0    0\n",
      "\n",
      "[1] 2 3 2\n"
     ]
    }
   ],
   "source": [
    "# a tensor\n",
    "\n",
    "(x = array(rep(0, 2*3*2), dim = c(2,3,2)) ) %>% str\n",
    "x %>% print\n",
    "x %>% dim %>% print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is defined by three key attributes:\n",
    "- **Number of axes** (rank): For instance, a 3D tensor has three axes, and a matrix has two axes.\n",
    "- **Shape**: This is an integer vector that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape (3, 5), and the 3D tensor example has shape (3, 3, 5) . A vector has a shape with a single element, such as (5). You can access the dimensions of any array using the dim() function.\n",
    "- **Data type**: This is the type of the data contained in the tensor; for instance, a tensor’s type could be integer ($\\texttt{int}$) or double $\\texttt{numeric}$. On rare occasions, you may see a character ($\\texttt{character}$) tensors. However, since tensors live in pre-allocated contiguous memory segments, and strings, being variable-length, would preclude the use of this implementation, they are more rarely used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few examples of tensors\n",
    "- *Vector data*: 2d tensors of shape ($\\texttt{samples}$, $\\texttt{feature}$)\n",
    "- *Timeseries data* or *sequence data*: 3d tensors of shape ($\\texttt{samples}$, $\\texttt{timesteps}$, $\\texttt{feature}$)\n",
    "- *Images*: 4d tensors of shape ($\\texttt{samples}$, $\\texttt{height}$, $\\texttt{width}$, $\\texttt{channels}$)\n",
    "- *Videos*: 5d tensors of shape ($\\texttt{samples}$, $\\texttt{frame}$, $\\texttt{height}$, $\\texttt{width}$, $\\texttt{channels}$)\n",
    "\n",
    "<img src=\"fig/2d_tensor.PNG\" width=\"400\"> <img src=\"fig/3d_tensor.PNG\" width=\"400\">\n",
    "\n",
    "### Batches: *slicing* tensors\n",
    "\n",
    "In general, the first axis in all data tensors you’ll come across in deep learning will be the $\\texttt{samples}$ axis. In the MNIST example, samples are images of digits. In addition, deep learning models do not process the entire dataset at once, rather, they break the data into small **batches** (whose size is determined in the $\\texttt{compile}$ method by the parameter - guess what - $\\texttt{batch}$\\_$\\texttt{size}$ )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating tensor\n",
    "Slicing can easily be extended to the others dimension of the tensor. This can be useful to inspect and/or select a particular set of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a batch of 128 images\n",
    "\n",
    "train_images = mnist$train$x\n",
    "batch = train_images[1:128,,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/PNG": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAFoCAMAAABNO5HnAAAC/VBMVEUAAAABAQECAgIDAwME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\naEwBNKb+H7C93gOk7M9nAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's plot a digit\n",
    "digit = batch[1,,]\n",
    "options(repr.plot.width=3, repr.plot.height=3)\n",
    "digit %>% as.raster(. ,max = 255) %>% plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/PNG": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAFoCAMAAABNO5HnAAAC/VBMVEUAAAABAQECAgIDAwME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\n6wAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's plot a zoomed digit\n",
    "digit_zoomed = batch[1,10:20,10:20]\n",
    "digit_zoomed %>% as.raster(. ,max = 255) %>% plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Tensor Operations\n",
    "\n",
    "All in all, you can interpret deep learning model as a chained tensor product.\n",
    "\n",
    "In our initial example, we were building our network by stacking dense layers on top of each other. A layer instance looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run\n",
    "layer_dense(units = 512, activation = \"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer can be interpreted as a function, which takes as input a 2D tensor and returns another 2D tensor—a new representation for the input tensor. Specifically, the function is as follows (where $\\texttt{W}$ is a 2D tensor (weight tensor) and $\\texttt{b}$ is a vector (bias tensor), both attributes of the layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run\n",
    "output = relu(dot(W, input) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s unpack this. We have **three tensor operations here** (at the core of tensorflow):\n",
    "- a **dot product** ($\\cdot$) between the input tensor and a tensor named $\\texttt{W}$,\n",
    "- an **addition** ($+$) between the resulting 2D tensor and a vector $\\texttt{b}$ , and finally\n",
    "- an **element-wise operation** ($\\texttt{relu}$). $\\texttt{relu(x)} = \\max(x, 0)$\n",
    "\n",
    "\n",
    "> A couple of concepts that will be deepened later on:\n",
    "\n",
    "> #### Bias\n",
    "> A vector. Equivalent of the intercept coefficient in any regression\n",
    "\n",
    "> #### Activation function\n",
    "> The equivalent of the logit function in a logistic regression. Used to introduce non-linearities in the network (wich would otherwise result in a mere linear transformation of the input, uncapable to grasp non-linear features).\n",
    "\n",
    "There is an additional operation worth mentioning, which is **tensor reshaping**: nothing more than rearranging its rows and columns to match a target shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    2    3\n",
      "[3,]    4    5\n"
     ]
    }
   ],
   "source": [
    "(x = matrix(c(0, 1, 2, 3, 4, 5),\n",
    "           nrow = 3,\n",
    "           ncol = 2,\n",
    "           byrow = TRUE)) %>% print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1]\n",
      "[1,]    0\n",
      "[2,]    1\n",
      "[3,]    2\n",
      "[4,]    3\n",
      "[5,]    4\n",
      "[6,]    5\n"
     ]
    }
   ],
   "source": [
    "# reshape to a vector\n",
    "(x = array_reshape(x, dim = c(6, 1))) %>% print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1] [,2] [,3]\n",
      "[1,]    0    1    2\n",
      "[2,]    3    4    5\n"
     ]
    }
   ],
   "source": [
    "# ri-reshape to a matrix\n",
    "(x = array_reshape(x, dim = c(2, 3))) %>% print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1] [,2]\n",
      "[1,]    0    3\n",
      "[2,]    1    4\n",
      "[3,]    2    5\n"
     ]
    }
   ],
   "source": [
    "# transpose back to its original shape\n",
    "(x = t(x) ) %>% print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric interpretation of deep learning\n",
    "\n",
    "You just learned that neural networks consist entirely of **chains of tensor operations** and that all of these tensor operations are just geometric transformations of the input data (in some n-dimentional hyperspace). It follows that you can interpret a neural network as a very complex geometric transformation in a high-dimensional space, implemented via a long series of simple\n",
    "steps.\n",
    "\n",
    "Imagine you need to discriminate which side is which in a crumpled paper sheet.\n",
    "\n",
    "<img src=\"fig/paper_ball.PNG\" width=\"400\">\n",
    "\n",
    "**Uncrumpling paper balls is what machine learning is about**: finding neat representations for complex, highly folded data manifolds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Gradient Based Optimization\n",
    "\n",
    "This is how things *really* come to be.\n",
    "\n",
    "As you saw in the previous section, each neural layer from our first network example transforms its input data as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run\n",
    "output = relu(dot(W, input) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this expression, $\\texttt{W}$ and $\\texttt{b}$ are tensors that are attributes of the layer. They’re called the *weights* or the *trainable parameters* of the layer (the $\\texttt{kernel}$ and $\\texttt{bias}$ attributes, respectively). These weights contain the information learned by the network from exposure to training data. Initially, these weight matrices are filled with small random values (a step called random initialization). Of course, there’s no reason to expect that $\\texttt{relu(dot(W, input) + b)}$, when $\\texttt{W}$ and $\\texttt{b}$ are random, would yield any useful representations. The resulting representations are meaningless but they are a starting point. What comes next is **to gradually adjust these weights, based on a feedback signal**. This gradual adjustment, also called training, is basically \"**the learning**\" that machine learning is all about.\n",
    "\n",
    "This happens within what's called a **training loop**, which schematically looks as follows:\n",
    "1. Draw a batch of training samples $\\texttt{x}$ and corresponding targets $\\texttt{y}$\n",
    "2. Run the network on $\\texttt{x}$ (this is called a **forward pass**, or feedforwading), to obtain predictions $\\texttt{y}$\\_$\\texttt{pred}$\n",
    "3. Compute the loss of the network on the batch, a measure of mismatch between $\\texttt{y}$\\_$\\texttt{pred}$ and $\\texttt{y}$\n",
    "4. Update all weights of the network in a way that slighly redices the loss on this batch\n",
    "\n",
    "You will eventually end up with a network that slighly reduces the loss on training data: that is, a low mismatch between predictions $\\texttt{y_pred}$ and expected targets $\\texttt{y}$. The network has *learned* to map its inputs to correct targets. From afar, it may look like magic, but when reduced to elementary steps, it turns out to be simple.\n",
    "\n",
    "Step 1 sounds easy enough: just I/O code. Steps 2 and 3 are merely the application of a handful of tensor operations, so you could implement these steps purely from what you learned in the previous section. The difficult part is step 4: updating the network’s\n",
    "weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]\n",
       "Variable(shape=(784, 512), dtype=float32_ref)\n",
       "\n",
       "\n",
       "[[2]]\n",
       "Variable(shape=(512,), dtype=float32_ref)\n",
       "\n",
       "\n",
       "[[3]]\n",
       "Variable(shape=(512, 10), dtype=float32_ref)\n",
       "\n",
       "\n",
       "[[4]]\n",
       "Variable(shape=(10,), dtype=float32_ref)\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# which are traineble parameters in our MNIST network\n",
    "network$trainable_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach is to take advantage of the fact that **all operations used in the network are compute the differentiable** , and to **compute the gradient of the loss with regard to the network’s coefficients**. You can then **move the coefficients in the opposite direction from the gradient**, thus decreasing the\n",
    "loss.\n",
    "\n",
    "> BTW a **gradient** is nothing more than a n-dimensional derivative, that is a **derivative of a tensor operation** (i.e. a matrix where on the main diagonal you find the derivative on a specific dimension, while partial derivative elsewere). This thing is also referred as the **Jacobian** matrix.\n",
    "\n",
    "<img src=\"fig/1d_loss.png\" width=\"200\"> <img src=\"fig/2d_loss.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Rule: the backpropagation algorithm\n",
    "\n",
    "In the previous algorithm, we casually assumed that because a function is differentiable, we can explicitly compute its derivative. In practice, a neural-network function consists of many tensor operations chained together, each of which has a simple, known derivative. For instance, this is a network $f$ composed of three tensor operations $a$, $b$, and $c$, with weight matrices $W1$, $W2$, and $W3$:\n",
    "\n",
    "$$f(W1, W2, W3) = a(W1,\\, b(W2,\\, c(W3))$$\n",
    "\n",
    "Calculus tells us that a chain of function can bedifferentiated using the so-called *chain rule*:\n",
    "\n",
    "$$\\frac{d}{dx}f(g(x)) = f'(g(x)) \\cdot g'(x)$$\n",
    "\n",
    "Recursively applying the chain rule to the coputation of the gradient values gives rise to an algorithm called *backpropagation*. Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, applying the chain rule to compute the contribution that each parameter had in the loss value.\n",
    "\n",
    "Modern frameworks, such as tensorflow, are capable of *symbolic differentiation*, which means that, given a chain of operations with a known derivative, they can compute a gradient function for the whole chain (by applying the chain rule), that **maps every network parameter to gradient values**. When you have access to such a function, the backward pass is simply reduced to a call to this gradient function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## WAIT. Please recap!\n",
    "Sure.\n",
    "\n",
    "- This was the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist <- dataset_mnist() train_images <- mnist$train$x\n",
    "\n",
    "train_images <- array_reshape(train_images, c(60000, 28 * 28))\n",
    "train_images <- train_images / 255\n",
    "test_images <- mnist$test$x\n",
    "test_images <- array_reshape(test_images, c(10000, 28 * 28))\n",
    "test_images <- test_images / 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now you understand that our **input images are stored in tensors** of shape $(60,000, 784)$ (training data) and $(10,000, 784)$ (testing data) redpectively.\n",
    "\n",
    "- This was our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = keras_model_sequential() %>% # keras_model_sequential is the basic call to start building the nnet\n",
    "            # first layer\n",
    "            layer_dense(units = 512,\n",
    "                        activation = \"relu\",\n",
    "                        input_shape = c(28 * 28),\n",
    "                        use_bias = T,\n",
    "                        name='first_layer'\n",
    "                       ) %>%\n",
    "            # second layer\n",
    "            layer_dense(units = 10,\n",
    "                        activation = \"softmax\",\n",
    "                        use_bias = T,\n",
    "                        name = 'output_layer'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you understand that\n",
    "1. this network consists in a **chain of two dense layer**, and that\n",
    "2. each layer applies a few simple tensor operations to the input data, that \n",
    "3. these operations involve tensors\n",
    "4.  weight tensors ($\\texttt{W}$ and $\\texttt{b}$), which are attributes of the layer, is where the **knowledge** of the network persist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This was the network-compilation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network %>% compile(optimizer = \"rmsprop\",\n",
    "                    loss = \"categorical_crossentropy\",\n",
    "                    metrics = c(\"accuracy\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you understand that\n",
    "1. $\\texttt{categorical}$\\_$\\texttt{crossentropy}$ is the loss funtion that is used as a feedback signal for learning the weight tensors (which the training phase will attempt to minimize)\n",
    "2. The reduction of the loss happens via gradient descent. The exact tules governing a specific use of gradient descent are defined by the $\\texttt{'rmsprop'}$ optimizer passed as the first argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this was the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network %>% fit(train_images,\n",
    "                train_labels,\n",
    "                epochs = 5,\n",
    "                batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you understand what's going on when you call $\\texttt{fit}$\n",
    "1. The network will start to iterate on the training data in batches of 128 samples\n",
    "2. The network will iterate over all batches five times (each iteration over all the training data is called an **epoch**)\n",
    "3. After these 5 epochs you will have performed 2,345 gradient updats (469 per epoch) and the loss of the network wukk be sufficiently low that the model will be capable to classify handwritten digits wih high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Final tips\n",
    "\n",
    "### 1.  Activation function\n",
    "Lots of activation function have been developed in time.\n",
    "\n",
    "#### Hidden layer\n",
    "Please use $\\texttt{relu}$ (Rectified linear unit). It is the simplest and it work the best!\n",
    "\n",
    "#### Output layer\n",
    "It depends:\n",
    "- **Binary classification**: use $\\texttt{'sigmoid'}$ \n",
    "- **Multiclass classification**\n",
    "    - **single outcome** possible at a time: use $\\texttt{'softmax'}$\n",
    "    - **multiple outcomes** possible at the same fime: use $\\texttt{'sigmoid'}$\n",
    "- **Regression to arbitrary values**: don't use any\n",
    "    - between O and 1? you can use $\\texttt{'sigmoid'}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'activation_elu'</li>\n",
       "\t<li>'activation_hard_sigmoid'</li>\n",
       "\t<li>'activation_linear'</li>\n",
       "\t<li>'activation_relu'</li>\n",
       "\t<li>'activation_selu'</li>\n",
       "\t<li>'activation_sigmoid'</li>\n",
       "\t<li>'activation_softmax'</li>\n",
       "\t<li>'activation_softplus'</li>\n",
       "\t<li>'activation_softsign'</li>\n",
       "\t<li>'activation_tanh'</li>\n",
       "\t<li>'layer_activation'</li>\n",
       "\t<li>'layer_activation_elu'</li>\n",
       "\t<li>'layer_activation_leaky_relu'</li>\n",
       "\t<li>'layer_activation_parametric_relu'</li>\n",
       "\t<li>'layer_activation_softmax'</li>\n",
       "\t<li>'layer_activation_thresholded_relu'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'activation\\_elu'\n",
       "\\item 'activation\\_hard\\_sigmoid'\n",
       "\\item 'activation\\_linear'\n",
       "\\item 'activation\\_relu'\n",
       "\\item 'activation\\_selu'\n",
       "\\item 'activation\\_sigmoid'\n",
       "\\item 'activation\\_softmax'\n",
       "\\item 'activation\\_softplus'\n",
       "\\item 'activation\\_softsign'\n",
       "\\item 'activation\\_tanh'\n",
       "\\item 'layer\\_activation'\n",
       "\\item 'layer\\_activation\\_elu'\n",
       "\\item 'layer\\_activation\\_leaky\\_relu'\n",
       "\\item 'layer\\_activation\\_parametric\\_relu'\n",
       "\\item 'layer\\_activation\\_softmax'\n",
       "\\item 'layer\\_activation\\_thresholded\\_relu'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'activation_elu'\n",
       "2. 'activation_hard_sigmoid'\n",
       "3. 'activation_linear'\n",
       "4. 'activation_relu'\n",
       "5. 'activation_selu'\n",
       "6. 'activation_sigmoid'\n",
       "7. 'activation_softmax'\n",
       "8. 'activation_softplus'\n",
       "9. 'activation_softsign'\n",
       "10. 'activation_tanh'\n",
       "11. 'layer_activation'\n",
       "12. 'layer_activation_elu'\n",
       "13. 'layer_activation_leaky_relu'\n",
       "14. 'layer_activation_parametric_relu'\n",
       "15. 'layer_activation_softmax'\n",
       "16. 'layer_activation_thresholded_relu'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"activation_elu\"                    \"activation_hard_sigmoid\"          \n",
       " [3] \"activation_linear\"                 \"activation_relu\"                  \n",
       " [5] \"activation_selu\"                   \"activation_sigmoid\"               \n",
       " [7] \"activation_softmax\"                \"activation_softplus\"              \n",
       " [9] \"activation_softsign\"               \"activation_tanh\"                  \n",
       "[11] \"layer_activation\"                  \"layer_activation_elu\"             \n",
       "[13] \"layer_activation_leaky_relu\"       \"layer_activation_parametric_relu\" \n",
       "[15] \"layer_activation_softmax\"          \"layer_activation_thresholded_relu\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsp(keras, pattern = 'activation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loss function\n",
    "It depends:\n",
    "- **Binary classification**: use $\\texttt{'binary_crossentropy'}$\n",
    "- **Multiclass classification**\n",
    "    - **single outcome** possible at a time: use $\\texttt{'categorical_crossentropy'}$\n",
    "    - **multiple outcomes** possible at the same fime: use $\\texttt{'binary_crossentropy'}$\n",
    "- **Regression to arbitrary values**: $\\texttt{'mse'}$\n",
    "    - between O and 1? you can use $\\texttt{'mse'}$ or $\\texttt{'binary_crossentropy'}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'loss_binary_crossentropy'</li>\n",
       "\t<li>'loss_categorical_crossentropy'</li>\n",
       "\t<li>'loss_categorical_hinge'</li>\n",
       "\t<li>'loss_cosine_proximity'</li>\n",
       "\t<li>'loss_hinge'</li>\n",
       "\t<li>'loss_kullback_leibler_divergence'</li>\n",
       "\t<li>'loss_logcosh'</li>\n",
       "\t<li>'loss_mean_absolute_error'</li>\n",
       "\t<li>'loss_mean_absolute_percentage_error'</li>\n",
       "\t<li>'loss_mean_squared_error'</li>\n",
       "\t<li>'loss_mean_squared_logarithmic_error'</li>\n",
       "\t<li>'loss_poisson'</li>\n",
       "\t<li>'loss_sparse_categorical_crossentropy'</li>\n",
       "\t<li>'loss_squared_hinge'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'loss\\_binary\\_crossentropy'\n",
       "\\item 'loss\\_categorical\\_crossentropy'\n",
       "\\item 'loss\\_categorical\\_hinge'\n",
       "\\item 'loss\\_cosine\\_proximity'\n",
       "\\item 'loss\\_hinge'\n",
       "\\item 'loss\\_kullback\\_leibler\\_divergence'\n",
       "\\item 'loss\\_logcosh'\n",
       "\\item 'loss\\_mean\\_absolute\\_error'\n",
       "\\item 'loss\\_mean\\_absolute\\_percentage\\_error'\n",
       "\\item 'loss\\_mean\\_squared\\_error'\n",
       "\\item 'loss\\_mean\\_squared\\_logarithmic\\_error'\n",
       "\\item 'loss\\_poisson'\n",
       "\\item 'loss\\_sparse\\_categorical\\_crossentropy'\n",
       "\\item 'loss\\_squared\\_hinge'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'loss_binary_crossentropy'\n",
       "2. 'loss_categorical_crossentropy'\n",
       "3. 'loss_categorical_hinge'\n",
       "4. 'loss_cosine_proximity'\n",
       "5. 'loss_hinge'\n",
       "6. 'loss_kullback_leibler_divergence'\n",
       "7. 'loss_logcosh'\n",
       "8. 'loss_mean_absolute_error'\n",
       "9. 'loss_mean_absolute_percentage_error'\n",
       "10. 'loss_mean_squared_error'\n",
       "11. 'loss_mean_squared_logarithmic_error'\n",
       "12. 'loss_poisson'\n",
       "13. 'loss_sparse_categorical_crossentropy'\n",
       "14. 'loss_squared_hinge'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"loss_binary_crossentropy\"            \n",
       " [2] \"loss_categorical_crossentropy\"       \n",
       " [3] \"loss_categorical_hinge\"              \n",
       " [4] \"loss_cosine_proximity\"               \n",
       " [5] \"loss_hinge\"                          \n",
       " [6] \"loss_kullback_leibler_divergence\"    \n",
       " [7] \"loss_logcosh\"                        \n",
       " [8] \"loss_mean_absolute_error\"            \n",
       " [9] \"loss_mean_absolute_percentage_error\" \n",
       "[10] \"loss_mean_squared_error\"             \n",
       "[11] \"loss_mean_squared_logarithmic_error\" \n",
       "[12] \"loss_poisson\"                        \n",
       "[13] \"loss_sparse_categorical_crossentropy\"\n",
       "[14] \"loss_squared_hinge\"                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsp(keras, pattern = 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Optimizer\n",
    "Lots of optimization function have been developed in time. Currently, for most of tasks, the adaptive moment estimation ($\\texttt{adam}$) optimizer works the best and converge to the mimimum loss faster than any other algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'optimizer_adadelta'</li>\n",
       "\t<li>'optimizer_adagrad'</li>\n",
       "\t<li>'optimizer_adam'</li>\n",
       "\t<li>'optimizer_adamax'</li>\n",
       "\t<li>'optimizer_nadam'</li>\n",
       "\t<li>'optimizer_rmsprop'</li>\n",
       "\t<li>'optimizer_sgd'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'optimizer\\_adadelta'\n",
       "\\item 'optimizer\\_adagrad'\n",
       "\\item 'optimizer\\_adam'\n",
       "\\item 'optimizer\\_adamax'\n",
       "\\item 'optimizer\\_nadam'\n",
       "\\item 'optimizer\\_rmsprop'\n",
       "\\item 'optimizer\\_sgd'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'optimizer_adadelta'\n",
       "2. 'optimizer_adagrad'\n",
       "3. 'optimizer_adam'\n",
       "4. 'optimizer_adamax'\n",
       "5. 'optimizer_nadam'\n",
       "6. 'optimizer_rmsprop'\n",
       "7. 'optimizer_sgd'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"optimizer_adadelta\" \"optimizer_adagrad\"  \"optimizer_adam\"    \n",
       "[4] \"optimizer_adamax\"   \"optimizer_nadam\"    \"optimizer_rmsprop\" \n",
       "[7] \"optimizer_sgd\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsp(keras, pattern = 'optimizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every hyperparameter you can choose whether to pass the string ($\\texttt{'adam'}$) or by calling the equivalent function $\\texttt{optimizer}$\\_$\\texttt{adam}$(), where you can additionally manually specify a few parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save model\n",
    "The training process may require a lot of time. You'd better save your model if you want to use it somewhere else without training it by scratch, or if you want to use any pre-trained model.\n",
    "\n",
    "A model is stored as a .hdf5 file. Please note what you will have to save separately the structure and the weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'save_model_hdf5'</li>\n",
       "\t<li>'save_model_weights_hdf5'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'save\\_model\\_hdf5'\n",
       "\\item 'save\\_model\\_weights\\_hdf5'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'save_model_hdf5'\n",
       "2. 'save_model_weights_hdf5'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"save_model_hdf5\"         \"save_model_weights_hdf5\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'load_model_hdf5'</li>\n",
       "\t<li>'load_model_weights_hdf5'</li>\n",
       "\t<li>'mobilenet_load_model_hdf5'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'load\\_model\\_hdf5'\n",
       "\\item 'load\\_model\\_weights\\_hdf5'\n",
       "\\item 'mobilenet\\_load\\_model\\_hdf5'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'load_model_hdf5'\n",
       "2. 'load_model_weights_hdf5'\n",
       "3. 'mobilenet_load_model_hdf5'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"load_model_hdf5\"           \"load_model_weights_hdf5\"  \n",
       "[3] \"mobilenet_load_model_hdf5\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsp(keras, pattern = 'save_model')\n",
    "lsp(keras, pattern = 'load_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make predictions\n",
    "You may want to predict something... classes? probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'predict_classes'</li>\n",
       "\t<li>'predict_generator'</li>\n",
       "\t<li>'predict_on_batch'</li>\n",
       "\t<li>'predict_proba'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'predict\\_classes'\n",
       "\\item 'predict\\_generator'\n",
       "\\item 'predict\\_on\\_batch'\n",
       "\\item 'predict\\_proba'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'predict_classes'\n",
       "2. 'predict_generator'\n",
       "3. 'predict_on_batch'\n",
       "4. 'predict_proba'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"predict_classes\"   \"predict_generator\" \"predict_on_batch\" \n",
       "[4] \"predict_proba\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsp(keras, pattern = 'predict_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
