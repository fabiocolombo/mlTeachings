{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newtork Regularization\n",
    "\n",
    "___\n",
    "\n",
    "*Source: [Chollet et al., Deep Learning With R](https://www.amazon.com/Deep-Learning-R-Francois-Chollet/dp/161729554X) *\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the examples in the previous chapter—predicting movie reviews, topic classification, and house-price regression—the performance of the model on the held-out validation data always peaked after a few epochs and then began to degrade: that is, the model quickly started to **overfit** to the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting happens in every machine learning problem (as we have seen). Learning how to deal with it is essential!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental issue in machine learning is the **trade-off between optimization and generalization**.\n",
    "Optimization refers to the process of adjusting a model to get the best performance possible on the training data (the learning machine learning ), whereas \n",
    "generalization refers to how well the trained model performs on data it has never seen before.\n",
    "The goal of the game is to get good generalization, of course, but you don’t\n",
    "control generalization; you can only adjust the model based on its training data.\n",
    "\n",
    "Always keep this in mind: deep-learning models tend to be good at fitting to the training data, but the real challenge is\n",
    "generalization, not fitting.\n",
    "\n",
    "> The process of fighting overfitting is called **regularization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "source('src/lib.R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the network we trained previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = load_model_hdf5('data/mnist_net.h5')\n",
    "network$load_weights('data/mnist_net_w.h5')\n",
    "\n",
    "# network %>% load_model_weights_hdf5('data/mnist_net_w.h5') # other possible way to load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "________________________________________________________________________________\n",
       "Layer (type)                        Output Shape                    Param #     \n",
       "================================================================================\n",
       "dense_1 (Dense)                     (None, 256)                     200960      \n",
       "________________________________________________________________________________\n",
       "dropout_1 (Dropout)                 (None, 256)                     0           \n",
       "________________________________________________________________________________\n",
       "dense_2 (Dense)                     (None, 128)                     32896       \n",
       "________________________________________________________________________________\n",
       "dropout_2 (Dropout)                 (None, 128)                     0           \n",
       "________________________________________________________________________________\n",
       "dense_3 (Dense)                     (None, 10)                      1290        \n",
       "================================================================================\n",
       "Total params: 235,146\n",
       "Trainable params: 235,146\n",
       "Non-trainable params: 0\n",
       "________________________________________________________________________________\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also load the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAAAv8QzMzNNTU1o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\n",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(history = readRDS('data/mnist_training_history.R')) %>% plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A short overfitting tale\n",
    "1. At the beginning of training, optimization and generalization are correlated: the lower the loss on training data, the lower the loss on test data. While this is happening, your model is said to be under-fit : there is still progress to be made; the network hasn’t yet modeled all relevant patterns in the training data.\n",
    "2. After a certain number of iterations on the training data, generalization stops improving, and validation metrics stall and then begin to degrade: the model is starting to over-fit. That is, it’s beginning to learn patterns that are specific to the training data but that are misleading or irrelevant when it comes to\n",
    "new data.\n",
    "3. End."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to deal with overfitting issues\n",
    "### Reducing the network's size\n",
    "The simplest way to prevent overfitting is to **reduce the capacity** (i.e. the size) of the model: that is, the number of learnable parameters in the model (which is determined by the number of layers and the number of units per layer). Intuitively, a model with more parameters has more memorization capacity and therefore can easily learn a perfect dictionary-like mapping between training samples and their targets—a mapping without any generalization power.\n",
    "\n",
    "On the other hand, if the network has limited memorization resources, it won’t be able to learn this mapping as easily; thus, in order to minimize its loss, **the model will have to resort to learning compressed representations that have predictive power regarding the targets** precisely the type of representations we’re interested in.\n",
    "\n",
    "At the same time, keep in mind that you should use models that have enough parameters that they don’t underfit: your model shouldn’t be starved for memorization resources. There is a compromise to be found between too much capacity and not enough capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding weight regularization\n",
    "\n",
    "You may be familiar with the principle of Occam’s razor : given two explanations for something, the explanation most likely to be correct is the simplest one—the one that makes fewer assumptions. This idea also applies to the models learned by neural networks: given some training data and a network architecture, multiple sets of weight values (multiple models ) could explain the data. Simpler models are less likely to overfit than complex ones. A\n",
    "simple model in this context is a model where the distribution of parameter values has less entropy (or a model with fewer parameters, as you saw in the previous section). Thus a common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights to take only small values, which makes the distribution of weight values more\n",
    "regular . This is called weight regularization , and it’s done by adding to the loss function of the network a cost associated with having large weights. This cost comes in two flavors:\n",
    "\n",
    "- **L1 regularization** The cost added is proportional to the absolute value of the weight (the coefficients L1 norm L2 regularization—The cost added is proportional to the square of the value of the (the of the weights). weight coefficients L2 norm of the weights).\n",
    "- **L2 regularization** is also called weight decay in the context of neural networks. Don’t let the different name confuse you: weight decay is mathematically the same as L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dropout\n",
    "Dropout is one of the most effective and most commonly used regularization techniques for neural networks, developed by Geoff Hinton and his students at the University of Toronto. Dropout, applied to a layer, consists of randomly dropping out (setting to zero) a number of output features of the layer during training. Let’s say a given layer would normally return a vector [0.2, 0.5, 1.3, 0.8, 1.1] for a given input sample during training. After applying dropout, this vector will have a few zero entries distributed at random: for example, [0, 0.5, 1.3, 0, 1.1].\n",
    "\n",
    "The dropout rate is the fraction of the feature that are zeroued out. It is usually set between 0.2 and 0.5. At test time, no units are dropped out; instead, the layer;s output values are scaled down by a dactor equal to the dropout rate, to balance for the fact that more units are acrive at a training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalin up: developing a model that overfits\n",
    "\n",
    "To figure out how big a model you’ll need, you must develop a model that overfits. This is fairly easy:\n",
    "- Add layers.\n",
    "- Make the layers bigger.\n",
    "- Train for more epochs.\n",
    "\n",
    "Always monitor the training loss and validation loss, as well as the training and validation values for any metrics you care about. When you see that the model’s performance on the validation data begins to degrade, you’ve achieved overfitting. The next stage is to start regularizing and tuning the model, to get as close as possible to the ideal model that neither underfits nor overfits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Regularizing your model and tuning your hyperparameters\n",
    "This step will take the most time: you’ll repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. These are some things you should try:\n",
    "- Add dropout.\n",
    "- Try different architectures: add or remove layers.\n",
    "- Add L1 and/or L2 regularization.\n",
    "- Try different hyperparameters (such as the number of units per layer or the learning rate of the optimizer) to find the optimal configuration.\n",
    "- Optionally, iterate on feature engineering: add new features, or remove features that don’t seem to be informative.\n",
    "\n",
    "Be mindful of the following: every time you use feedback from your validation process to tune your model, you leak information about the validation process into the model. Repeated just a few times, this is innocuous; but done systematically over many iterations, it will eventually cause your model to overfit to the validation process (even though no model is directly trained on any of the validation data). This makes the evaluation process less reliable, so keep it in mind.\n",
    "Once you’ve developed a good enough model configuration, you can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set. If it turns out that performance on the test set is significantly worse than the performance measured on the validation data, this may mean either that your validation procedure wasn’t reliable after all, or that you started overfitting to the validation data while tuning the parameters of the model. In this case, you may want to switch to a more reliable evaluation protocol (such as iterated K-fold validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
