{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Extraction\n",
    "\n",
    "`nltk` is a language toolkit for python. Entity extraction relies on a dictionary to classify words. Here we download a library that will tag english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno -2] Name or service not known>\n",
      "[nltk_data] Error loading maxent_ne_chunker: <urlopen error [Errno -2]\n",
      "[nltk_data]     Name or service not known>\n",
      "[nltk_data] Error loading words: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trolls = pd.read_csv(\"data/trolls.csv\")\n",
    "X, y = (trolls[\"Comment\"], trolls[\"Insult\"])\n",
    "\n",
    "samples = X.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have the main code. The only new bit is the tagging and combining of words.\n",
    "\n",
    "The tagging process takes a word and converts it into a type. Types are denoted by a code.\n",
    "\n",
    "Once the words are tagged, they are then grouped. Note that tags of the same type are not necessarily merged. It depends on the rules provided by the chunker (which are provided by another dictionary of settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_NE(sample, debug=False):\n",
    "    # Split sentences\n",
    "    sentences = nltk.sent_tokenize(sample)\n",
    "    # Split words\n",
    "    tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    # Tag words\n",
    "    tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "    # Combine tags\n",
    "    chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=False)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"input:\\n\", sample, \"\\n\")\n",
    "        print(\"sentences:\\n\", sentences, \"\\n\")\n",
    "        print(\"tokens:\\n\", tokenized_sentences, \"\\n\")\n",
    "        print(\"tagged:\\n\", tagged_sentences, \"\\n\")\n",
    "    \n",
    "    def extract_entity_names(t):\n",
    "        entity_names = []\n",
    "        if hasattr(t, 'label') and t.label:\n",
    "            if t.label() in [\"NE\", \"ORGANIZATION\", \"PERSON\", \"LOCATION\"]:\n",
    "                entity_names.append(' '.join([child[0] for child in t]))\n",
    "            else:\n",
    "                for child in t:\n",
    "                    entity_names.extend(extract_entity_names(child))\n",
    "        return entity_names\n",
    "\n",
    "    entity_names = []\n",
    "    debug_chunks = []\n",
    "    for tree in chunked_sentences:\n",
    "        debug_chunks.append(tree)\n",
    "        entity_names.extend(extract_entity_names(tree))\n",
    "\n",
    "    if debug:\n",
    "        print(\"chunked:\\n\", debug_chunks, \"\\n\")\n",
    "        print(set(entity_names))\n",
    "    return set(entity_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " \"Quote from Teresa May \"That is why we have been trying to deport him to Jordan, his home country.\" TRYING - Since when does a Sovereign have problems TRYING to deport diseased minded scum like him. Stuff the EU laws and if the UK is \\\\'fined\\\\' by the EUSSR for doing this then don\\\\'t pay it ... and then stop all financial payments to this corrupt experiment. It doesn\\\\'t work, its broke so listen to the PEOPLE Camoron and have an in or out referendum .. NOW!\" \n",
      "\n",
      "sentences:\n",
      " ['\"Quote from Teresa May \"That is why we have been trying to deport him to Jordan, his home country.\"', 'TRYING - Since when does a Sovereign have problems TRYING to deport diseased minded scum like him.', \"Stuff the EU laws and if the UK is \\\\\\\\'fined\\\\\\\\' by the EUSSR for doing this then don\\\\\\\\'t pay it ... and then stop all financial payments to this corrupt experiment.\", \"It doesn\\\\\\\\'t work, its broke so listen to the PEOPLE Camoron and have an in or out referendum ..\", 'NOW!\"'] \n",
      "\n",
      "tokens:\n",
      " [['``', 'Quote', 'from', 'Teresa', 'May', '``', 'That', 'is', 'why', 'we', 'have', 'been', 'trying', 'to', 'deport', 'him', 'to', 'Jordan', ',', 'his', 'home', 'country', '.', \"''\"], ['TRYING', '-', 'Since', 'when', 'does', 'a', 'Sovereign', 'have', 'problems', 'TRYING', 'to', 'deport', 'diseased', 'minded', 'scum', 'like', 'him', '.'], ['Stuff', 'the', 'EU', 'laws', 'and', 'if', 'the', 'UK', 'is', \"\\\\\\\\'fined\\\\\\\\\", \"'\", 'by', 'the', 'EUSSR', 'for', 'doing', 'this', 'then', \"don\\\\\\\\'t\", 'pay', 'it', '...', 'and', 'then', 'stop', 'all', 'financial', 'payments', 'to', 'this', 'corrupt', 'experiment', '.'], ['It', \"doesn\\\\\\\\'t\", 'work', ',', 'its', 'broke', 'so', 'listen', 'to', 'the', 'PEOPLE', 'Camoron', 'and', 'have', 'an', 'in', 'or', 'out', 'referendum', '..'], ['NOW', '!', \"''\"]] \n",
      "\n",
      "tagged:\n",
      " [[('``', '``'), ('Quote', 'NN'), ('from', 'IN'), ('Teresa', 'NNP'), ('May', 'NNP'), ('``', '``'), ('That', 'DT'), ('is', 'VBZ'), ('why', 'WRB'), ('we', 'PRP'), ('have', 'VBP'), ('been', 'VBN'), ('trying', 'VBG'), ('to', 'TO'), ('deport', 'VB'), ('him', 'PRP'), ('to', 'TO'), ('Jordan', 'NNP'), (',', ','), ('his', 'PRP$'), ('home', 'NN'), ('country', 'NN'), ('.', '.'), (\"''\", \"''\")], [('TRYING', 'SYM'), ('-', ':'), ('Since', 'IN'), ('when', 'WRB'), ('does', 'VBZ'), ('a', 'DT'), ('Sovereign', 'NNP'), ('have', 'VBP'), ('problems', 'NNS'), ('TRYING', 'VBP'), ('to', 'TO'), ('deport', 'VB'), ('diseased', 'VBN'), ('minded', 'JJ'), ('scum', 'NNS'), ('like', 'IN'), ('him', 'PRP'), ('.', '.')], [('Stuff', 'NNP'), ('the', 'DT'), ('EU', 'NNP'), ('laws', 'NNS'), ('and', 'CC'), ('if', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('is', 'VBZ'), (\"\\\\\\\\'fined\\\\\\\\\", 'NNP'), (\"'\", 'POS'), ('by', 'IN'), ('the', 'DT'), ('EUSSR', 'NNP'), ('for', 'IN'), ('doing', 'VBG'), ('this', 'DT'), ('then', 'RB'), (\"don\\\\\\\\'t\", 'VBZ'), ('pay', 'VB'), ('it', 'PRP'), ('...', ':'), ('and', 'CC'), ('then', 'RB'), ('stop', 'VB'), ('all', 'DT'), ('financial', 'JJ'), ('payments', 'NNS'), ('to', 'TO'), ('this', 'DT'), ('corrupt', 'JJ'), ('experiment', 'NN'), ('.', '.')], [('It', 'PRP'), (\"doesn\\\\\\\\'t\", 'VBZ'), ('work', 'NN'), (',', ','), ('its', 'PRP$'), ('broke', 'VBD'), ('so', 'RB'), ('listen', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('PEOPLE', 'NNP'), ('Camoron', 'NNP'), ('and', 'CC'), ('have', 'VBP'), ('an', 'DT'), ('in', 'IN'), ('or', 'CC'), ('out', 'IN'), ('referendum', 'NN'), ('..', 'NN')], [('NOW', 'NN'), ('!', '.'), (\"''\", \"''\")]] \n",
      "\n",
      "chunked:\n",
      " [Tree('S', [('``', '``'), ('Quote', 'NN'), ('from', 'IN'), Tree('PERSON', [('Teresa', 'NNP'), ('May', 'NNP')]), ('``', '``'), ('That', 'DT'), ('is', 'VBZ'), ('why', 'WRB'), ('we', 'PRP'), ('have', 'VBP'), ('been', 'VBN'), ('trying', 'VBG'), ('to', 'TO'), ('deport', 'VB'), ('him', 'PRP'), ('to', 'TO'), Tree('GPE', [('Jordan', 'NNP')]), (',', ','), ('his', 'PRP$'), ('home', 'NN'), ('country', 'NN'), ('.', '.'), (\"''\", \"''\")]), Tree('S', [('TRYING', 'SYM'), ('-', ':'), ('Since', 'IN'), ('when', 'WRB'), ('does', 'VBZ'), ('a', 'DT'), ('Sovereign', 'NNP'), ('have', 'VBP'), ('problems', 'NNS'), ('TRYING', 'VBP'), ('to', 'TO'), ('deport', 'VB'), ('diseased', 'VBN'), ('minded', 'JJ'), ('scum', 'NNS'), ('like', 'IN'), ('him', 'PRP'), ('.', '.')]), Tree('S', [('Stuff', 'NNP'), ('the', 'DT'), Tree('GPE', [('EU', 'NNP')]), ('laws', 'NNS'), ('and', 'CC'), ('if', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('UK', 'NNP')]), ('is', 'VBZ'), (\"\\\\\\\\'fined\\\\\\\\\", 'NNP'), (\"'\", 'POS'), ('by', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('EUSSR', 'NNP')]), ('for', 'IN'), ('doing', 'VBG'), ('this', 'DT'), ('then', 'RB'), (\"don\\\\\\\\'t\", 'VBZ'), ('pay', 'VB'), ('it', 'PRP'), ('...', ':'), ('and', 'CC'), ('then', 'RB'), ('stop', 'VB'), ('all', 'DT'), ('financial', 'JJ'), ('payments', 'NNS'), ('to', 'TO'), ('this', 'DT'), ('corrupt', 'JJ'), ('experiment', 'NN'), ('.', '.')]), Tree('S', [('It', 'PRP'), (\"doesn\\\\\\\\'t\", 'VBZ'), ('work', 'NN'), (',', ','), ('its', 'PRP$'), ('broke', 'VBD'), ('so', 'RB'), ('listen', 'JJ'), ('to', 'TO'), ('the', 'DT'), Tree('ORGANIZATION', [('PEOPLE', 'NNP'), ('Camoron', 'NNP')]), ('and', 'CC'), ('have', 'VBP'), ('an', 'DT'), ('in', 'IN'), ('or', 'CC'), ('out', 'IN'), ('referendum', 'NN'), ('..', 'NN')]), Tree('S', [('NOW', 'NN'), ('!', '.'), (\"''\", \"''\")])] \n",
      "\n",
      "{'Teresa May', 'EUSSR', 'UK', 'PEOPLE Camoron'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EUSSR', 'PEOPLE Camoron', 'Teresa May', 'UK'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_NE(samples[182], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "- Think about how to take this data and classify it.\n",
    "- Try and create a classifier. Does it work better? Worse? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
