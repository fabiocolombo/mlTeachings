{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand Challenge - Text\n",
    "\n",
    "Now it's time to get those thinking caps on. \n",
    "\n",
    "In this big example, you'll be creating an algorithm to predict the sentiment (i.e. good/bad) of thousands of movie reviews.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Given some text, correctly predict whether the text is a positive or a negative review.\n",
    "\n",
    "## Data\n",
    "\n",
    "This data comes from the IMDB movie review dataset. The data is replicated over the internet, but this data came from the Kaggle competition of the same name. Yes, that's right, it's competition time!\n",
    "\n",
    "I've formatted the data for you.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "All you need to do is to take the arrays of raw text, write the algorithm and predict the results.\n",
    "\n",
    "## Results\n",
    "\n",
    "We will compare results. The winner will get to show their results to the rest of the class and also recieve bragging rights!\n",
    "\n",
    "## Baselines\n",
    "\n",
    "Below 70%, try harder. 70-75%, doing ok. 75-80%, pretty good. 80-85%, very good. 85-90%, you'll probably win. 90%+ that's world class. Only sophisitcated linear models or neural networks can get that high.\n",
    "\n",
    "## Answers\n",
    "\n",
    "As always, there's my answer in the answers folder. Only consult this if you're really stuck. To be honest I'd rather you ask for help or pair up in a team. This section is all about doing it for yourself.\n",
    "\n",
    "## Tips:\n",
    "\n",
    "- Try different classifiers (this seems to be more important that improving the text?)\n",
    "- Neural networks for binary classification?\n",
    "- Ensembles?\n",
    "- Don't prioritise cleaning the text. The data are already pretty clean.\n",
    "- Make sure you cross-validate to get a proper score. I will be checking the winner!\n",
    "- Reduce the amount of data whilst iterating. Don't waste time using the whole dataset, do that at\n",
    "  the end.\n",
    "- Use a grid search to do final tuning of algorithm hyper-parameters\n",
    "\n",
    "## Scoring\n",
    "\n",
    "I have provided a test set that should be used to generate your final score. You shouldn't need this\n",
    "until the end. Don't cheat! ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"data/movie.tsv\", delimiter=\"\\t\")\n",
    "# X = X[:5000] # Make the dataset smaller when iterating through your analysis. Faster feedback loop.\n",
    "X, y = (X[\"review\"], X[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "X = pd.read_csv(\"data/movie_test.tsv\", delimiter=\"\\t\")\n",
    "X, y = (X[\"review\"], X[\"sentiment\"])\n",
    "X = clean(X)\n",
    "X_counts = tfidf_vect.transform(X)\n",
    "score = clf.score(X_counts, y)\n",
    "print(\"Final Competition Score: %0.3f\" % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
